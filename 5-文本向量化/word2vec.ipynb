{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b8ef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.book import *\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm import tqdm_notebook\n",
    "import joblib\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f2ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist( raw_review, remove_stopwords=False ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))                  \n",
    "        words = [w for w in words if not w in stops]   \n",
    "    \n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return words\n",
    "\n",
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence,remove_stopwords ))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fef6929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014975786209106445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 72550,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf3e6311f6a4f5a9a269ae462c300a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           city  latitude  longitude                 attacktype1_txt  \\\n",
      "0      0.181904  0.681564   0.204755                   Armed Assault   \n",
      "1      0.688351  0.688223   0.106546               Bombing/Explosion   \n",
      "2      0.558561  0.732945   0.204053  Facility/Infrastructure Attack   \n",
      "3      0.558561  0.732914   0.204130  Facility/Infrastructure Attack   \n",
      "4      0.249211  0.704869   0.158102  Facility/Infrastructure Attack   \n",
      "...         ...       ...        ...                             ...   \n",
      "72545  0.009873  0.477141   0.603580               Bombing/Explosion   \n",
      "72546  0.142187  0.611361   0.713903  Facility/Infrastructure Attack   \n",
      "72547  0.787440  0.497927   0.597584               Bombing/Explosion   \n",
      "72548  0.420521  0.660566   0.675203                   Armed Assault   \n",
      "72549  0.974123  0.687351   0.180508                   Assassination   \n",
      "\n",
      "                                        targsubtype1_txt  \\\n",
      "0        Police Building (headquarters, station, school)   \n",
      "1                                            Electricity   \n",
      "2                    Military Recruiting Station/Academy   \n",
      "3                    Government Building/Facility/Office   \n",
      "4                    Military Recruiting Station/Academy   \n",
      "...                                                  ...   \n",
      "72545                                  International NGO   \n",
      "72546  Government Personnel (excluding police, military)   \n",
      "72547                          House/Apartment/Residence   \n",
      "72548                                          Protester   \n",
      "72549                                          Personnel   \n",
      "\n",
      "                                weapsubtype1_txt      date  risk  \\\n",
      "0                               Unknown Gun Type  0.500000     1   \n",
      "1                         Unknown Explosive Type  0.666667     1   \n",
      "2                   Molotov Cocktail/Petrol Bomb  0.666667     1   \n",
      "3                            Gasoline or Alcohol  0.833333     1   \n",
      "4                   Molotov Cocktail/Petrol Bomb  0.166667     1   \n",
      "...                                          ...       ...   ...   \n",
      "72545                     Unknown Explosive Type  0.500000     1   \n",
      "72546                        Gasoline or Alcohol  0.500000     1   \n",
      "72547  Projectile (rockets, mortars, RPGs, etc.)  0.500000     1   \n",
      "72548                           Unknown Gun Type  0.500000     2   \n",
      "72549                                    Handgun  0.500000     2   \n",
      "\n",
      "                                                 summary  \n",
      "0       unknown african american assailants fired sev...  \n",
      "1       unknown perpetrators detonated explosives at ...  \n",
      "2       karl armstrong, a member of the new years gan...  \n",
      "3       karl armstrong, a member of the new years gan...  \n",
      "4       unknown perpetrators threw a molotov cocktail...  \n",
      "...                                                  ...  \n",
      "72545   an explosive device detonated targeting the o...  \n",
      "72546   assailants set fire to the vehicle of ganesh ...  \n",
      "72547   assailants fired mortar shells targeting resi...  \n",
      "72548   no group claimed responsibility for the incident  \n",
      "72549   an assailant opened fire on dr. george tiller...  \n",
      "\n",
      "[72550 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../Bag of Word/data_txt.csv\")\n",
    "for row in tqdm_notebook(range(data.summary.shape[0])):\n",
    "    data.summary[row] = data.summary[row].lower()\n",
    "# print(data.summary)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc10437",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_txt.csv', index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0969b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n",
      "185471\n"
     ]
    }
   ],
   "source": [
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "print(\"Parsing sentences from training set\")\n",
    "for review in data[\"summary\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79495fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the word2vec of words...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02396678924560547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 14,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601b6e05c6d7457a80324dd0144b7756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:52:38,699 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:52:38,700 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:52:38,735 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:52:38,770 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:52:38,809 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n",
      "2023-09-17 09:52:38,838 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:52:38,865 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:52:38,891 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:52:38,917 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:52:38,944 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:52:38,968 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:52:38,991 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:52:39,021 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:52:39,044 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:52:39,067 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:52:39,092 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n",
      "2023-09-17 09:52:39,120 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:52:39,144 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:52:39,165 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:52:39,191 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:52:39,202 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:52:39,203 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:52:39,261 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:52:39.261204', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:52:39,262 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:52:39.262161', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:52:39,328 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:52:39,329 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:52:39,329 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:52:39.329981', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:52:39,436 : INFO : estimated required memory for 11477 words and 100 dimensions: 14920100 bytes\n",
      "2023-09-17 09:52:39,436 : INFO : resetting layer weights\n",
      "2023-09-17 09:52:39,484 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:52:39.484925', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:52:39,485 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:52:39.485948', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:52:40,492 : INFO : EPOCH 0 - PROGRESS: at 89.75% examples, 1331102 words/s, in_qsize 6, out_qsize 0\n",
      "2023-09-17 09:52:40,565 : INFO : EPOCH 0: training on 2416409 raw words (1453624 effective words) took 1.1s, 1355070 effective words/s\n",
      "2023-09-17 09:52:41,600 : INFO : EPOCH 1: training on 2416409 raw words (1453335 effective words) took 0.9s, 1630701 effective words/s\n",
      "2023-09-17 09:52:42,511 : INFO : EPOCH 2: training on 2416409 raw words (1453731 effective words) took 0.9s, 1605770 effective words/s\n",
      "2023-09-17 09:52:43,415 : INFO : EPOCH 3: training on 2416409 raw words (1453554 effective words) took 0.9s, 1618028 effective words/s\n",
      "2023-09-17 09:52:44,337 : INFO : EPOCH 4: training on 2416409 raw words (1454192 effective words) took 0.9s, 1584316 effective words/s\n",
      "2023-09-17 09:52:44,338 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7268436 effective words) took 4.9s, 1498072 effective words/s', 'datetime': '2023-09-17T09:52:44.338668', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:52:44,339 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=100, alpha=0.025>', 'datetime': '2023-09-17T09:52:44.339664', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:52:44,340 : INFO : Word2Vec lifecycle event {'fname_or_handle': '100features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:52:44.340680', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:52:44,341 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:52:44,353 : INFO : saved 100features_word2vec\n",
      "2023-09-17 09:52:44,355 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:52:44,355 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:52:44,387 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:52:44,416 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:52:44,452 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n",
      "2023-09-17 09:52:44,477 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:52:44,501 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:52:44,523 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:52:44,546 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:52:44,568 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:52:44,592 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:52:44,612 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:52:44,634 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:52:44,657 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:52:44,678 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:52:44,699 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:52:44,722 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:52:44,745 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:52:44,768 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:52:44,787 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:52:44,800 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:52:44,801 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:52:44,858 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:52:44.858990', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:52:44,859 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:52:44.859953', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:52:44,927 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:52:44,928 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:52:44,928 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:52:44.928802', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:52:45,042 : INFO : estimated required memory for 11477 words and 200 dimensions: 24101700 bytes\n",
      "2023-09-17 09:52:45,043 : INFO : resetting layer weights\n",
      "2023-09-17 09:52:45,054 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:52:45.054467', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:52:45,055 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:52:45.055437', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:52:46,065 : INFO : EPOCH 0 - PROGRESS: at 96.80% examples, 1409487 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:52:46,093 : INFO : EPOCH 0: training on 2416409 raw words (1454176 effective words) took 1.0s, 1409155 effective words/s\n",
      "2023-09-17 09:52:47,102 : INFO : EPOCH 1 - PROGRESS: at 95.01% examples, 1388616 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:52:47,149 : INFO : EPOCH 1: training on 2416409 raw words (1454211 effective words) took 1.1s, 1384150 effective words/s\n",
      "2023-09-17 09:52:48,163 : INFO : EPOCH 2 - PROGRESS: at 90.71% examples, 1334742 words/s, in_qsize 6, out_qsize 0\n",
      "2023-09-17 09:52:48,243 : INFO : EPOCH 2: training on 2416409 raw words (1453869 effective words) took 1.1s, 1337321 effective words/s\n",
      "2023-09-17 09:52:49,250 : INFO : EPOCH 3 - PROGRESS: at 96.80% examples, 1415063 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:52:49,274 : INFO : EPOCH 3: training on 2416409 raw words (1454963 effective words) took 1.0s, 1419151 effective words/s\n",
      "2023-09-17 09:52:50,281 : INFO : EPOCH 4 - PROGRESS: at 98.70% examples, 1436181 words/s, in_qsize 3, out_qsize 0\n",
      "2023-09-17 09:52:50,290 : INFO : EPOCH 4: training on 2416409 raw words (1454247 effective words) took 1.0s, 1438167 effective words/s\n",
      "2023-09-17 09:52:50,292 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7271466 effective words) took 5.2s, 1388767 effective words/s', 'datetime': '2023-09-17T09:52:50.292426', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:52:50,293 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=200, alpha=0.025>', 'datetime': '2023-09-17T09:52:50.293421', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:52:50,295 : INFO : Word2Vec lifecycle event {'fname_or_handle': '200features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:52:50.295443', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:52:50,296 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:52:50,313 : INFO : saved 200features_word2vec\n",
      "2023-09-17 09:52:50,316 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:52:50,317 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:52:50,354 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:52:50,383 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:52:50,415 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n",
      "2023-09-17 09:52:50,438 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:52:50,461 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:52:50,487 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:52:50,509 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:52:50,531 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:52:50,553 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:52:50,575 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:52:50,599 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:52:50,621 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:52:50,641 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:52:50,661 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n",
      "2023-09-17 09:52:50,682 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:52:50,706 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:52:50,725 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:52:50,748 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:52:50,761 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:52:50,761 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:52:50,819 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:52:50.819698', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:52:50,820 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:52:50.820695', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:52:50,885 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:52:50,887 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:52:50,888 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:52:50.888481', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:52:50,999 : INFO : estimated required memory for 11477 words and 300 dimensions: 33283300 bytes\n",
      "2023-09-17 09:52:50,999 : INFO : resetting layer weights\n",
      "2023-09-17 09:52:51,015 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:52:51.015169', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:52:51,015 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:52:51.015169', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:52:52,024 : INFO : EPOCH 0 - PROGRESS: at 69.79% examples, 1084267 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:52:52,336 : INFO : EPOCH 0: training on 2416409 raw words (1453872 effective words) took 1.3s, 1106164 effective words/s\n",
      "2023-09-17 09:52:53,344 : INFO : EPOCH 1 - PROGRESS: at 77.23% examples, 1174373 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:52:53,584 : INFO : EPOCH 1: training on 2416409 raw words (1453586 effective words) took 1.2s, 1170370 effective words/s\n",
      "2023-09-17 09:52:54,595 : INFO : EPOCH 2 - PROGRESS: at 75.87% examples, 1154384 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:52:54,843 : INFO : EPOCH 2: training on 2416409 raw words (1454354 effective words) took 1.3s, 1159095 effective words/s\n",
      "2023-09-17 09:52:55,857 : INFO : EPOCH 3 - PROGRESS: at 74.48% examples, 1135210 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:52:56,121 : INFO : EPOCH 3: training on 2416409 raw words (1454722 effective words) took 1.3s, 1144731 effective words/s\n",
      "2023-09-17 09:52:57,130 : INFO : EPOCH 4 - PROGRESS: at 74.48% examples, 1139843 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:52:57,420 : INFO : EPOCH 4: training on 2416409 raw words (1453907 effective words) took 1.3s, 1124049 effective words/s\n",
      "2023-09-17 09:52:57,421 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7270441 effective words) took 6.4s, 1135061 effective words/s', 'datetime': '2023-09-17T09:52:57.421641', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:52:57,421 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=300, alpha=0.025>', 'datetime': '2023-09-17T09:52:57.421641', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:52:57,424 : INFO : Word2Vec lifecycle event {'fname_or_handle': '300features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:52:57.424633', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:52:57,426 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:52:57,448 : INFO : saved 300features_word2vec\n",
      "2023-09-17 09:52:57,450 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:52:57,451 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:52:57,481 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:52:57,510 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:52:57,539 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n",
      "2023-09-17 09:52:57,564 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:52:57,588 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:52:57,610 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:52:57,636 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:52:57,660 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:52:57,682 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:52:57,701 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:52:57,724 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:52:57,748 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:52:57,770 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:52:57,790 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n",
      "2023-09-17 09:52:57,811 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:52:57,832 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:52:57,856 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:52:57,880 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:52:57,891 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:52:57,892 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:52:57,948 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:52:57.948057', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:52:57,948 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:52:57.948057', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:52:58,017 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:52:58,019 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:52:58,021 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:52:58.021829', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:52:58,129 : INFO : estimated required memory for 11477 words and 400 dimensions: 42464900 bytes\n",
      "2023-09-17 09:52:58,130 : INFO : resetting layer weights\n",
      "2023-09-17 09:52:58,151 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:52:58.151510', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:52:58,152 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 400 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:52:58.152478', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:52:59,162 : INFO : EPOCH 0 - PROGRESS: at 59.96% examples, 964390 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:52:59,622 : INFO : EPOCH 0: training on 2416409 raw words (1454441 effective words) took 1.5s, 993800 effective words/s\n",
      "2023-09-17 09:53:00,639 : INFO : EPOCH 1 - PROGRESS: at 64.01% examples, 1016709 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:01,035 : INFO : EPOCH 1: training on 2416409 raw words (1454989 effective words) took 1.4s, 1039452 effective words/s\n",
      "2023-09-17 09:53:02,042 : INFO : EPOCH 2 - PROGRESS: at 70.68% examples, 1097944 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:02,354 : INFO : EPOCH 2: training on 2416409 raw words (1454452 effective words) took 1.3s, 1107581 effective words/s\n",
      "2023-09-17 09:53:03,361 : INFO : EPOCH 3 - PROGRESS: at 55.82% examples, 914539 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:03,968 : INFO : EPOCH 3: training on 2416409 raw words (1454151 effective words) took 1.6s, 904046 effective words/s\n",
      "2023-09-17 09:53:04,980 : INFO : EPOCH 4 - PROGRESS: at 59.04% examples, 951057 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:05,422 : INFO : EPOCH 4: training on 2416409 raw words (1454213 effective words) took 1.4s, 1004180 effective words/s\n",
      "2023-09-17 09:53:05,423 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7272246 effective words) took 7.3s, 1000253 effective words/s', 'datetime': '2023-09-17T09:53:05.423818', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:53:05,424 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=400, alpha=0.025>', 'datetime': '2023-09-17T09:53:05.424814', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:53:05,427 : INFO : Word2Vec lifecycle event {'fname_or_handle': '400features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:53:05.427806', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:53:05,428 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:53:05,559 : INFO : saved 400features_word2vec\n",
      "2023-09-17 09:53:05,561 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:53:05,562 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:53:05,592 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:53:05,622 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:53:05,653 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n",
      "2023-09-17 09:53:05,675 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:53:05,699 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:53:05,720 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:53:05,741 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:53:05,764 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:53:05,791 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:53:05,811 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:53:05,833 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:53:05,859 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:53:05,886 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:53:05,907 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n",
      "2023-09-17 09:53:05,931 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:53:05,957 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:53:05,981 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:53:06,003 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:53:06,014 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:53:06,015 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:53:06,073 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:53:06.073019', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:06,073 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:53:06.073988', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:06,137 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:53:06,139 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:53:06,140 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:53:06.140812', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:06,257 : INFO : estimated required memory for 11477 words and 500 dimensions: 51646500 bytes\n",
      "2023-09-17 09:53:06,258 : INFO : resetting layer weights\n",
      "2023-09-17 09:53:06,285 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:53:06.285159', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:53:06,286 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:53:06.286118', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:53:07,294 : INFO : EPOCH 0 - PROGRESS: at 47.35% examples, 803072 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:08,062 : INFO : EPOCH 0: training on 2416409 raw words (1454177 effective words) took 1.8s, 821379 effective words/s\n",
      "2023-09-17 09:53:09,071 : INFO : EPOCH 1 - PROGRESS: at 53.14% examples, 878574 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:09,727 : INFO : EPOCH 1: training on 2416409 raw words (1454294 effective words) took 1.7s, 876805 effective words/s\n",
      "2023-09-17 09:53:10,734 : INFO : EPOCH 2 - PROGRESS: at 49.13% examples, 827342 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:11,419 : INFO : EPOCH 2: training on 2416409 raw words (1453813 effective words) took 1.7s, 862033 effective words/s\n",
      "2023-09-17 09:53:12,429 : INFO : EPOCH 3 - PROGRESS: at 47.35% examples, 802125 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:13,177 : INFO : EPOCH 3: training on 2416409 raw words (1454748 effective words) took 1.8s, 830184 effective words/s\n",
      "2023-09-17 09:53:14,184 : INFO : EPOCH 4 - PROGRESS: at 50.94% examples, 850129 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:14,929 : INFO : EPOCH 4: training on 2416409 raw words (1454011 effective words) took 1.7s, 832316 effective words/s\n",
      "2023-09-17 09:53:14,930 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7271043 effective words) took 8.6s, 841215 effective words/s', 'datetime': '2023-09-17T09:53:14.930824', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:53:14,930 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=500, alpha=0.025>', 'datetime': '2023-09-17T09:53:14.930824', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:53:14,934 : INFO : Word2Vec lifecycle event {'fname_or_handle': '500features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:53:14.934812', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:53:14,934 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:53:15,023 : INFO : saved 500features_word2vec\n",
      "2023-09-17 09:53:15,026 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:53:15,027 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:53:15,059 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:53:15,090 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:53:15,123 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n",
      "2023-09-17 09:53:15,147 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:53:15,170 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:53:15,193 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:53:15,214 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:53:15,234 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:53:15,254 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:53:15,277 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:53:15,297 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:53:15,317 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:53:15,336 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:53:15,355 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n",
      "2023-09-17 09:53:15,377 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:53:15,397 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:53:15,415 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:53:15,435 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:53:15,446 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:53:15,446 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:53:15,503 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:53:15.503626', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:15,503 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:53:15.503626', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:15,565 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:53:15,566 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:53:15,568 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:53:15.568417', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:15,695 : INFO : estimated required memory for 11477 words and 600 dimensions: 60828100 bytes\n",
      "2023-09-17 09:53:15,696 : INFO : resetting layer weights\n",
      "2023-09-17 09:53:15,726 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:53:15.726994', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:53:15,727 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 600 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:53:15.727991', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:53:16,739 : INFO : EPOCH 0 - PROGRESS: at 43.75% examples, 755249 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:17,605 : INFO : EPOCH 0: training on 2416409 raw words (1454708 effective words) took 1.9s, 777152 effective words/s\n",
      "2023-09-17 09:53:18,613 : INFO : EPOCH 1 - PROGRESS: at 47.35% examples, 803846 words/s, in_qsize 6, out_qsize 0\n",
      "2023-09-17 09:53:19,464 : INFO : EPOCH 1: training on 2416409 raw words (1454074 effective words) took 1.9s, 784566 effective words/s\n",
      "2023-09-17 09:53:20,475 : INFO : EPOCH 2 - PROGRESS: at 44.64% examples, 767080 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:21,276 : INFO : EPOCH 2: training on 2416409 raw words (1454332 effective words) took 1.8s, 805295 effective words/s\n",
      "2023-09-17 09:53:22,286 : INFO : EPOCH 3 - PROGRESS: at 38.50% examples, 688275 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:23,282 : INFO : EPOCH 3: training on 2416409 raw words (1454116 effective words) took 2.0s, 727604 effective words/s\n",
      "2023-09-17 09:53:24,291 : INFO : EPOCH 4 - PROGRESS: at 47.79% examples, 809980 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:25,066 : INFO : EPOCH 4: training on 2416409 raw words (1455080 effective words) took 1.8s, 818780 effective words/s\n",
      "2023-09-17 09:53:25,067 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7272310 effective words) took 9.3s, 778788 effective words/s', 'datetime': '2023-09-17T09:53:25.067011', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:53:25,067 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=600, alpha=0.025>', 'datetime': '2023-09-17T09:53:25.067011', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:53:25,072 : INFO : Word2Vec lifecycle event {'fname_or_handle': '600features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:53:25.072036', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:53:25,072 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:53:25,392 : INFO : saved 600features_word2vec\n",
      "2023-09-17 09:53:25,395 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:53:25,396 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:53:25,426 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:53:25,453 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:53:25,485 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:53:25,510 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:53:25,536 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:53:25,563 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:53:25,588 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:53:25,613 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:53:25,635 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:53:25,657 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:53:25,678 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:53:25,699 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:53:25,718 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:53:25,737 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n",
      "2023-09-17 09:53:25,758 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:53:25,778 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:53:25,798 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:53:25,817 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:53:25,830 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:53:25,832 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:53:25,887 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:53:25.887408', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:25,887 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:53:25.887408', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:25,952 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:53:25,953 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:53:25,954 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:53:25.954197', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:26,062 : INFO : estimated required memory for 11477 words and 700 dimensions: 70009700 bytes\n",
      "2023-09-17 09:53:26,063 : INFO : resetting layer weights\n",
      "2023-09-17 09:53:26,096 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:53:26.096842', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:53:26,096 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 700 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:53:26.096842', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:53:27,104 : INFO : EPOCH 0 - PROGRESS: at 40.26% examples, 711628 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:28,071 : INFO : EPOCH 0: training on 2416409 raw words (1454435 effective words) took 2.0s, 738789 effective words/s\n",
      "2023-09-17 09:53:29,078 : INFO : EPOCH 1 - PROGRESS: at 41.98% examples, 735867 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:30,001 : INFO : EPOCH 1: training on 2416409 raw words (1454989 effective words) took 1.9s, 756038 effective words/s\n",
      "2023-09-17 09:53:31,014 : INFO : EPOCH 2 - PROGRESS: at 42.41% examples, 740232 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:31,949 : INFO : EPOCH 2: training on 2416409 raw words (1453669 effective words) took 1.9s, 751027 effective words/s\n",
      "2023-09-17 09:53:32,965 : INFO : EPOCH 3 - PROGRESS: at 41.98% examples, 727350 words/s, in_qsize 6, out_qsize 0\n",
      "2023-09-17 09:53:33,894 : INFO : EPOCH 3: training on 2416409 raw words (1454129 effective words) took 1.9s, 749078 effective words/s\n",
      "2023-09-17 09:53:34,916 : INFO : EPOCH 4 - PROGRESS: at 42.84% examples, 735657 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:35,917 : INFO : EPOCH 4 - PROGRESS: at 97.75% examples, 707866 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:35,946 : INFO : EPOCH 4: training on 2416409 raw words (1455080 effective words) took 2.0s, 711142 effective words/s\n",
      "2023-09-17 09:53:35,947 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7272302 effective words) took 9.8s, 738336 effective words/s', 'datetime': '2023-09-17T09:53:35.947486', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:53:35,947 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=700, alpha=0.025>', 'datetime': '2023-09-17T09:53:35.947486', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:53:35,952 : INFO : Word2Vec lifecycle event {'fname_or_handle': '700features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:53:35.952440', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:53:35,953 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:53:36,501 : INFO : saved 700features_word2vec\n",
      "2023-09-17 09:53:36,503 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:53:36,505 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:53:36,533 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:53:36,562 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:53:36,595 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n",
      "2023-09-17 09:53:36,618 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:53:36,640 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:53:36,661 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:53:36,681 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:53:36,701 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:53:36,722 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:53:36,741 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:53:36,763 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:53:36,785 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:53:36,803 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:53:36,823 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:53:36,843 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:53:36,865 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:53:36,885 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:53:36,908 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:53:36,920 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:53:36,922 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:53:36,981 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:53:36.981485', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:36,981 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:53:36.981485', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:37,050 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:53:37,052 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:53:37,053 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:53:37.053260', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:37,181 : INFO : estimated required memory for 11477 words and 800 dimensions: 79191300 bytes\n",
      "2023-09-17 09:53:37,181 : INFO : resetting layer weights\n",
      "2023-09-17 09:53:37,221 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:53:37.221810', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:53:37,222 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 800 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:53:37.222806', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:53:38,228 : INFO : EPOCH 0 - PROGRESS: at 36.78% examples, 666129 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:39,239 : INFO : EPOCH 0 - PROGRESS: at 92.62% examples, 678723 words/s, in_qsize 6, out_qsize 0\n",
      "2023-09-17 09:53:39,353 : INFO : EPOCH 0: training on 2416409 raw words (1453630 effective words) took 2.1s, 683965 effective words/s\n",
      "2023-09-17 09:53:40,362 : INFO : EPOCH 1 - PROGRESS: at 34.69% examples, 634710 words/s, in_qsize 6, out_qsize 0\n",
      "2023-09-17 09:53:41,365 : INFO : EPOCH 1 - PROGRESS: at 83.30% examples, 624212 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:41,763 : INFO : EPOCH 1: training on 2416409 raw words (1454628 effective words) took 2.4s, 604895 effective words/s\n",
      "2023-09-17 09:53:42,789 : INFO : EPOCH 2 - PROGRESS: at 29.92% examples, 561331 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:43,792 : INFO : EPOCH 2 - PROGRESS: at 75.87% examples, 573490 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:44,313 : INFO : EPOCH 2: training on 2416409 raw words (1453360 effective words) took 2.5s, 571299 effective words/s\n",
      "2023-09-17 09:53:45,324 : INFO : EPOCH 3 - PROGRESS: at 29.50% examples, 563859 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:46,326 : INFO : EPOCH 3 - PROGRESS: at 74.48% examples, 569742 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:46,811 : INFO : EPOCH 3: training on 2416409 raw words (1455457 effective words) took 2.5s, 583610 effective words/s\n",
      "2023-09-17 09:53:47,828 : INFO : EPOCH 4 - PROGRESS: at 27.81% examples, 536730 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:48,829 : INFO : EPOCH 4 - PROGRESS: at 74.48% examples, 568064 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:49,384 : INFO : EPOCH 4: training on 2416409 raw words (1453849 effective words) took 2.6s, 566282 effective words/s\n",
      "2023-09-17 09:53:49,384 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7270924 effective words) took 12.2s, 597889 effective words/s', 'datetime': '2023-09-17T09:53:49.384507', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:53:49,385 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=800, alpha=0.025>', 'datetime': '2023-09-17T09:53:49.385504', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:53:49,391 : INFO : Word2Vec lifecycle event {'fname_or_handle': '800features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:53:49.391487', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:53:49,392 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:53:50,113 : INFO : saved 800features_word2vec\n",
      "2023-09-17 09:53:50,116 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:53:50,117 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:53:50,148 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:53:50,183 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:53:50,219 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n",
      "2023-09-17 09:53:50,247 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:53:50,274 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:53:50,297 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:53:50,321 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:53:50,349 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:53:50,373 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:53:50,395 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:53:50,417 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:53:50,441 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:53:50,462 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:53:50,485 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n",
      "2023-09-17 09:53:50,506 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:53:50,531 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:53:50,552 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:53:50,575 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:53:50,587 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:53:50,588 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:53:50,646 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:53:50.646939', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:53:50,647 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:53:50.647909', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:50,715 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:53:50,717 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:53:50,718 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:53:50.718720', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:53:50,839 : INFO : estimated required memory for 11477 words and 900 dimensions: 88372900 bytes\n",
      "2023-09-17 09:53:50,840 : INFO : resetting layer weights\n",
      "2023-09-17 09:53:50,888 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:53:50.888267', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:53:50,890 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 900 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:53:50.890261', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:53:51,909 : INFO : EPOCH 0 - PROGRESS: at 18.56% examples, 405105 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:52,913 : INFO : EPOCH 0 - PROGRESS: at 55.82% examples, 453531 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:53,918 : INFO : EPOCH 0 - PROGRESS: at 99.17% examples, 477481 words/s, in_qsize 2, out_qsize 1\n",
      "2023-09-17 09:53:53,926 : INFO : EPOCH 0: training on 2416409 raw words (1453621 effective words) took 3.0s, 479700 effective words/s\n",
      "2023-09-17 09:53:54,936 : INFO : EPOCH 1 - PROGRESS: at 26.96% examples, 528987 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:55,944 : INFO : EPOCH 1 - PROGRESS: at 69.79% examples, 540039 words/s, in_qsize 6, out_qsize 0\n",
      "2023-09-17 09:53:56,582 : INFO : EPOCH 1: training on 2416409 raw words (1453532 effective words) took 2.6s, 548704 effective words/s\n",
      "2023-09-17 09:53:57,589 : INFO : EPOCH 2 - PROGRESS: at 27.38% examples, 536457 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:58,595 : INFO : EPOCH 2 - PROGRESS: at 71.17% examples, 550147 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:53:59,207 : INFO : EPOCH 2: training on 2416409 raw words (1454500 effective words) took 2.6s, 555215 effective words/s\n",
      "2023-09-17 09:54:00,217 : INFO : EPOCH 3 - PROGRESS: at 28.22% examples, 547233 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:01,221 : INFO : EPOCH 3 - PROGRESS: at 73.07% examples, 561152 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:01,795 : INFO : EPOCH 3: training on 2416409 raw words (1454286 effective words) took 2.6s, 563302 effective words/s\n",
      "2023-09-17 09:54:02,814 : INFO : EPOCH 4 - PROGRESS: at 26.96% examples, 524744 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:03,820 : INFO : EPOCH 4 - PROGRESS: at 71.17% examples, 547085 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:04,413 : INFO : EPOCH 4: training on 2416409 raw words (1453430 effective words) took 2.6s, 556584 effective words/s\n",
      "2023-09-17 09:54:04,414 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7269369 effective words) took 13.5s, 537498 effective words/s', 'datetime': '2023-09-17T09:54:04.414924', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:54:04,415 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=900, alpha=0.025>', 'datetime': '2023-09-17T09:54:04.415908', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:54:04,421 : INFO : Word2Vec lifecycle event {'fname_or_handle': '900features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:54:04.421919', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:54:04,422 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:54:06,163 : INFO : saved 900features_word2vec\n",
      "2023-09-17 09:54:06,165 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:54:06,167 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:54:06,195 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:54:06,225 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:54:06,258 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n",
      "2023-09-17 09:54:06,284 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:54:06,308 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:54:06,332 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:54:06,357 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:54:06,380 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:54:06,401 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:54:06,423 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:54:06,445 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:54:06,468 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:54:06,489 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:54:06,512 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n",
      "2023-09-17 09:54:06,535 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:54:06,557 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:54:06,579 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:54:06,618 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:54:06,631 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:54:06,632 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:54:06,691 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:54:06.691248', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:54:06,692 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:54:06.692253', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:54:06,759 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:54:06,761 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:54:06,762 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:54:06.762059', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:54:06,883 : INFO : estimated required memory for 11477 words and 1000 dimensions: 97554500 bytes\n",
      "2023-09-17 09:54:06,884 : INFO : resetting layer weights\n",
      "2023-09-17 09:54:06,936 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:54:06.936592', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:54:06,937 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 1000 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:54:06.937602', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:54:07,951 : INFO : EPOCH 0 - PROGRESS: at 21.94% examples, 454832 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:08,954 : INFO : EPOCH 0 - PROGRESS: at 63.11% examples, 501146 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:09,774 : INFO : EPOCH 0: training on 2416409 raw words (1455364 effective words) took 2.8s, 513941 effective words/s\n",
      "2023-09-17 09:54:10,794 : INFO : EPOCH 1 - PROGRESS: at 26.53% examples, 517868 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:11,799 : INFO : EPOCH 1 - PROGRESS: at 66.90% examples, 521870 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:12,585 : INFO : EPOCH 1: training on 2416409 raw words (1454514 effective words) took 2.8s, 518514 effective words/s\n",
      "2023-09-17 09:54:13,596 : INFO : EPOCH 2 - PROGRESS: at 26.10% examples, 516547 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:14,603 : INFO : EPOCH 2 - PROGRESS: at 68.82% examples, 534875 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:15,301 : INFO : EPOCH 2: training on 2416409 raw words (1454103 effective words) took 2.7s, 536651 effective words/s\n",
      "2023-09-17 09:54:16,311 : INFO : EPOCH 3 - PROGRESS: at 26.53% examples, 522085 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:17,312 : INFO : EPOCH 3 - PROGRESS: at 69.79% examples, 541942 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:17,981 : INFO : EPOCH 3: training on 2416409 raw words (1454026 effective words) took 2.7s, 543652 effective words/s\n",
      "2023-09-17 09:54:19,007 : INFO : EPOCH 4 - PROGRESS: at 26.53% examples, 514733 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:20,015 : INFO : EPOCH 4 - PROGRESS: at 69.30% examples, 533353 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:20,684 : INFO : EPOCH 4: training on 2416409 raw words (1454213 effective words) took 2.7s, 539229 effective words/s\n",
      "2023-09-17 09:54:20,685 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7272220 effective words) took 13.7s, 528982 effective words/s', 'datetime': '2023-09-17T09:54:20.685359', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:54:20,685 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=1000, alpha=0.025>', 'datetime': '2023-09-17T09:54:20.685359', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:54:20,692 : INFO : Word2Vec lifecycle event {'fname_or_handle': '1000features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:54:20.692342', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:54:20,693 : INFO : storing np array 'vectors' to 1000features_word2vec.wv.vectors.npy\n",
      "2023-09-17 09:54:21,139 : INFO : storing np array 'syn1neg' to 1000features_word2vec.syn1neg.npy\n",
      "2023-09-17 09:54:22,637 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:54:22,644 : INFO : saved 1000features_word2vec\n",
      "2023-09-17 09:54:22,646 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:54:22,647 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:54:22,676 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:54:22,707 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:54:22,741 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n",
      "2023-09-17 09:54:22,766 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:54:22,790 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:54:22,813 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:54:22,837 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:54:22,860 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:54:22,886 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:54:22,914 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:54:22,940 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:54:22,966 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:54:22,990 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:54:23,014 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n",
      "2023-09-17 09:54:23,039 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:54:23,064 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:54:23,088 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:54:23,113 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:54:23,126 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:54:23,127 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:54:23,190 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:54:23.190232', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:54:23,192 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:54:23.192237', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:54:23,266 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:54:23,269 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:54:23,270 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:54:23.270018', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:54:23,409 : INFO : estimated required memory for 11477 words and 1100 dimensions: 106736100 bytes\n",
      "2023-09-17 09:54:23,411 : INFO : resetting layer weights\n",
      "2023-09-17 09:54:23,466 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:54:23.466517', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:54:23,467 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 1100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:54:23.467488', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:54:24,492 : INFO : EPOCH 0 - PROGRESS: at 19.81% examples, 420448 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:25,501 : INFO : EPOCH 0 - PROGRESS: at 56.28% examples, 454372 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:26,505 : INFO : EPOCH 0 - PROGRESS: at 95.01% examples, 459405 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:26,623 : INFO : EPOCH 0: training on 2416409 raw words (1454397 effective words) took 3.2s, 461668 effective words/s\n",
      "2023-09-17 09:54:27,629 : INFO : EPOCH 1 - PROGRESS: at 20.24% examples, 434755 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:28,636 : INFO : EPOCH 1 - PROGRESS: at 55.82% examples, 456240 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:29,652 : INFO : EPOCH 1 - PROGRESS: at 96.34% examples, 466436 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:29,727 : INFO : EPOCH 1: training on 2416409 raw words (1454606 effective words) took 3.1s, 469267 effective words/s\n",
      "2023-09-17 09:54:30,741 : INFO : EPOCH 2 - PROGRESS: at 21.53% examples, 449515 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:31,746 : INFO : EPOCH 2 - PROGRESS: at 58.12% examples, 469306 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:32,768 : INFO : EPOCH 2 - PROGRESS: at 97.28% examples, 468385 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:32,823 : INFO : EPOCH 2: training on 2416409 raw words (1453745 effective words) took 3.1s, 470524 effective words/s\n",
      "2023-09-17 09:54:33,837 : INFO : EPOCH 3 - PROGRESS: at 21.94% examples, 455826 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:34,858 : INFO : EPOCH 3 - PROGRESS: at 59.49% examples, 474346 words/s, in_qsize 6, out_qsize 0\n",
      "2023-09-17 09:54:35,859 : INFO : EPOCH 3 - PROGRESS: at 99.62% examples, 478585 words/s, in_qsize 1, out_qsize 1\n",
      "2023-09-17 09:54:35,860 : INFO : EPOCH 3: training on 2416409 raw words (1454465 effective words) took 3.0s, 479947 effective words/s\n",
      "2023-09-17 09:54:36,877 : INFO : EPOCH 4 - PROGRESS: at 22.36% examples, 459400 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:37,878 : INFO : EPOCH 4 - PROGRESS: at 58.58% examples, 472255 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:38,883 : INFO : EPOCH 4 - PROGRESS: at 98.22% examples, 475162 words/s, in_qsize 4, out_qsize 0\n",
      "2023-09-17 09:54:38,918 : INFO : EPOCH 4: training on 2416409 raw words (1455087 effective words) took 3.1s, 476710 effective words/s\n",
      "2023-09-17 09:54:38,919 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7272300 effective words) took 15.5s, 470671 effective words/s', 'datetime': '2023-09-17T09:54:38.919218', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:54:38,919 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=1100, alpha=0.025>', 'datetime': '2023-09-17T09:54:38.919218', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:54:38,925 : INFO : Word2Vec lifecycle event {'fname_or_handle': '1100features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:54:38.925201', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:54:38,926 : INFO : storing np array 'vectors' to 1100features_word2vec.wv.vectors.npy\n",
      "2023-09-17 09:54:40,053 : INFO : storing np array 'syn1neg' to 1100features_word2vec.syn1neg.npy\n",
      "2023-09-17 09:54:40,448 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:54:40,455 : INFO : saved 1100features_word2vec\n",
      "2023-09-17 09:54:40,458 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:54:40,459 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:54:40,491 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:54:40,522 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:54:40,555 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n",
      "2023-09-17 09:54:40,580 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:54:40,607 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:54:40,630 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:54:40,652 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:54:40,675 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:54:40,697 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:54:40,720 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:54:40,742 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:54:40,767 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:54:40,788 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:54:40,810 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n",
      "2023-09-17 09:54:40,832 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:54:40,856 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:54:40,879 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:54:40,900 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:54:40,913 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:54:40,913 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:54:40,974 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:54:40.974110', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:54:40,975 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:54:40.975105', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:54:41,046 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:54:41,047 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:54:41,048 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:54:41.048874', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:54:41,170 : INFO : estimated required memory for 11477 words and 1200 dimensions: 115917700 bytes\n",
      "2023-09-17 09:54:41,171 : INFO : resetting layer weights\n",
      "2023-09-17 09:54:41,230 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:54:41.230421', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:54:41,231 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 1200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:54:41.231385', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:54:42,239 : INFO : EPOCH 0 - PROGRESS: at 20.24% examples, 433631 words/s, in_qsize 6, out_qsize 0\n",
      "2023-09-17 09:54:43,245 : INFO : EPOCH 0 - PROGRESS: at 54.92% examples, 450111 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:44,247 : INFO : EPOCH 0 - PROGRESS: at 93.58% examples, 457048 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:44,405 : INFO : EPOCH 0: training on 2416409 raw words (1453628 effective words) took 3.2s, 458709 effective words/s\n",
      "2023-09-17 09:54:45,415 : INFO : EPOCH 1 - PROGRESS: at 21.10% examples, 445162 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:46,441 : INFO : EPOCH 1 - PROGRESS: at 56.74% examples, 456482 words/s, in_qsize 4, out_qsize 1\n",
      "2023-09-17 09:54:47,444 : INFO : EPOCH 1 - PROGRESS: at 95.89% examples, 463036 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:47,537 : INFO : EPOCH 1: training on 2416409 raw words (1453834 effective words) took 3.1s, 464865 effective words/s\n",
      "2023-09-17 09:54:48,557 : INFO : EPOCH 2 - PROGRESS: at 21.53% examples, 445945 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:49,573 : INFO : EPOCH 2 - PROGRESS: at 56.74% examples, 456290 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:50,581 : INFO : EPOCH 2 - PROGRESS: at 95.45% examples, 460150 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:50,688 : INFO : EPOCH 2: training on 2416409 raw words (1453719 effective words) took 3.1s, 462177 effective words/s\n",
      "2023-09-17 09:54:51,693 : INFO : EPOCH 3 - PROGRESS: at 20.67% examples, 440279 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:52,704 : INFO : EPOCH 3 - PROGRESS: at 54.02% examples, 443529 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:53,712 : INFO : EPOCH 3 - PROGRESS: at 93.11% examples, 453771 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:53,880 : INFO : EPOCH 3: training on 2416409 raw words (1453365 effective words) took 3.2s, 456046 effective words/s\n",
      "2023-09-17 09:54:54,890 : INFO : EPOCH 4 - PROGRESS: at 19.40% examples, 420451 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:55,903 : INFO : EPOCH 4 - PROGRESS: at 50.49% examples, 419313 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:56,925 : INFO : EPOCH 4 - PROGRESS: at 89.28% examples, 436419 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:54:57,179 : INFO : EPOCH 4: training on 2416409 raw words (1454811 effective words) took 3.3s, 441595 effective words/s\n",
      "2023-09-17 09:54:57,180 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7269357 effective words) took 15.9s, 455785 effective words/s', 'datetime': '2023-09-17T09:54:57.180866', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:54:57,180 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=1200, alpha=0.025>', 'datetime': '2023-09-17T09:54:57.180866', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:54:57,188 : INFO : Word2Vec lifecycle event {'fname_or_handle': '1200features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:54:57.188836', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:54:57,188 : INFO : storing np array 'vectors' to 1200features_word2vec.wv.vectors.npy\n",
      "2023-09-17 09:54:57,404 : INFO : storing np array 'syn1neg' to 1200features_word2vec.syn1neg.npy\n",
      "2023-09-17 09:54:57,787 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:54:57,793 : INFO : saved 1200features_word2vec\n",
      "2023-09-17 09:54:57,796 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:54:57,798 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:54:57,828 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:54:57,861 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:54:57,894 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n",
      "2023-09-17 09:54:57,918 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:54:57,941 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:54:57,964 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:54:57,987 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:54:58,009 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:54:58,033 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:54:58,057 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:54:58,078 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:54:58,103 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:54:58,125 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:54:58,147 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n",
      "2023-09-17 09:54:58,171 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:54:58,194 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:54:58,214 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:54:58,236 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:54:58,249 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:54:58,250 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:54:58,308 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:54:58.308993', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:54:58,310 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:54:58.310604', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:54:58,379 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:54:58,381 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:54:58,382 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:54:58.382414', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:54:58,504 : INFO : estimated required memory for 11477 words and 1300 dimensions: 125099300 bytes\n",
      "2023-09-17 09:54:58,504 : INFO : resetting layer weights\n",
      "2023-09-17 09:54:58,567 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:54:58.567951', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:54:58,568 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 1300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:54:58.568915', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:54:59,586 : INFO : EPOCH 0 - PROGRESS: at 17.37% examples, 385820 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:00,588 : INFO : EPOCH 0 - PROGRESS: at 46.42% examples, 394205 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:01,616 : INFO : EPOCH 0 - PROGRESS: at 78.19% examples, 391138 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:02,293 : INFO : EPOCH 0: training on 2416409 raw words (1454435 effective words) took 3.7s, 391113 effective words/s\n",
      "2023-09-17 09:55:03,333 : INFO : EPOCH 1 - PROGRESS: at 13.01% examples, 282012 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:04,342 : INFO : EPOCH 1 - PROGRESS: at 34.25% examples, 309351 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:05,343 : INFO : EPOCH 1 - PROGRESS: at 63.57% examples, 333367 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:06,351 : INFO : EPOCH 1 - PROGRESS: at 96.34% examples, 348343 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:06,461 : INFO : EPOCH 1: training on 2416409 raw words (1454989 effective words) took 4.2s, 349558 effective words/s\n",
      "2023-09-17 09:55:07,510 : INFO : EPOCH 2 - PROGRESS: at 14.68% examples, 317741 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:08,517 : INFO : EPOCH 2 - PROGRESS: at 37.22% examples, 327720 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:09,539 : INFO : EPOCH 2 - PROGRESS: at 64.47% examples, 333807 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:10,546 : INFO : EPOCH 2 - PROGRESS: at 91.66% examples, 332013 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:10,793 : INFO : EPOCH 2: training on 2416409 raw words (1454345 effective words) took 4.3s, 336274 effective words/s\n",
      "2023-09-17 09:55:11,809 : INFO : EPOCH 3 - PROGRESS: at 14.68% examples, 327805 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:12,837 : INFO : EPOCH 3 - PROGRESS: at 40.26% examples, 349799 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:13,840 : INFO : EPOCH 3 - PROGRESS: at 70.25% examples, 359427 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:14,737 : INFO : EPOCH 3: training on 2416409 raw words (1454881 effective words) took 3.9s, 369453 effective words/s\n",
      "2023-09-17 09:55:15,751 : INFO : EPOCH 4 - PROGRESS: at 16.75% examples, 374029 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:16,754 : INFO : EPOCH 4 - PROGRESS: at 45.97% examples, 391532 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:17,758 : INFO : EPOCH 4 - PROGRESS: at 78.19% examples, 394322 words/s, in_qsize 6, out_qsize 0\n",
      "2023-09-17 09:55:18,461 : INFO : EPOCH 4: training on 2416409 raw words (1453264 effective words) took 3.7s, 390792 effective words/s\n",
      "2023-09-17 09:55:18,462 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7271914 effective words) took 19.9s, 365559 effective words/s', 'datetime': '2023-09-17T09:55:18.462159', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:55:18,463 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=1300, alpha=0.025>', 'datetime': '2023-09-17T09:55:18.463158', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:55:18,472 : INFO : Word2Vec lifecycle event {'fname_or_handle': '1300features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:55:18.472133', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:55:18,473 : INFO : storing np array 'vectors' to 1300features_word2vec.wv.vectors.npy\n",
      "2023-09-17 09:55:19,210 : INFO : storing np array 'syn1neg' to 1300features_word2vec.syn1neg.npy\n",
      "2023-09-17 09:55:19,931 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:55:19,938 : INFO : saved 1300features_word2vec\n",
      "2023-09-17 09:55:19,941 : INFO : collecting all words and their counts\n",
      "2023-09-17 09:55:19,941 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-17 09:55:19,971 : INFO : PROGRESS: at sentence #10000, processed 177801 words, keeping 12644 word types\n",
      "2023-09-17 09:55:20,003 : INFO : PROGRESS: at sentence #20000, processed 353986 words, keeping 18738 word types\n",
      "2023-09-17 09:55:20,038 : INFO : PROGRESS: at sentence #30000, processed 540343 words, keeping 24165 word types\n",
      "2023-09-17 09:55:20,063 : INFO : PROGRESS: at sentence #40000, processed 680196 words, keeping 27078 word types\n",
      "2023-09-17 09:55:20,089 : INFO : PROGRESS: at sentence #50000, processed 809119 words, keeping 29534 word types\n",
      "2023-09-17 09:55:20,113 : INFO : PROGRESS: at sentence #60000, processed 934692 words, keeping 31772 word types\n",
      "2023-09-17 09:55:20,137 : INFO : PROGRESS: at sentence #70000, processed 1060909 words, keeping 33895 word types\n",
      "2023-09-17 09:55:20,162 : INFO : PROGRESS: at sentence #80000, processed 1185015 words, keeping 35949 word types\n",
      "2023-09-17 09:55:20,184 : INFO : PROGRESS: at sentence #90000, processed 1305579 words, keeping 37785 word types\n",
      "2023-09-17 09:55:20,206 : INFO : PROGRESS: at sentence #100000, processed 1426624 words, keeping 39754 word types\n",
      "2023-09-17 09:55:20,234 : INFO : PROGRESS: at sentence #110000, processed 1544737 words, keeping 41751 word types\n",
      "2023-09-17 09:55:20,259 : INFO : PROGRESS: at sentence #120000, processed 1663639 words, keeping 43964 word types\n",
      "2023-09-17 09:55:20,280 : INFO : PROGRESS: at sentence #130000, processed 1775115 words, keeping 46005 word types\n",
      "2023-09-17 09:55:20,302 : INFO : PROGRESS: at sentence #140000, processed 1890293 words, keeping 47975 word types\n",
      "2023-09-17 09:55:20,325 : INFO : PROGRESS: at sentence #150000, processed 2006321 words, keeping 50381 word types\n",
      "2023-09-17 09:55:20,347 : INFO : PROGRESS: at sentence #160000, processed 2123258 words, keeping 52895 word types\n",
      "2023-09-17 09:55:20,369 : INFO : PROGRESS: at sentence #170000, processed 2238039 words, keeping 55368 word types\n",
      "2023-09-17 09:55:20,392 : INFO : PROGRESS: at sentence #180000, processed 2353367 words, keeping 57813 word types\n",
      "2023-09-17 09:55:20,405 : INFO : collected 58963 word types from a corpus of 2416409 raw words and 185471 sentences\n",
      "2023-09-17 09:55:20,406 : INFO : Creating a fresh vocabulary\n",
      "2023-09-17 09:55:20,465 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11477 unique words (19.46% of original 58963, drops 47486)', 'datetime': '2023-09-17T09:55:20.465502', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:55:20,466 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2346601 word corpus (97.11% of original 2416409, drops 69808)', 'datetime': '2023-09-17T09:55:20.466466', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:55:20,534 : INFO : deleting the raw counts dictionary of 58963 items\n",
      "2023-09-17 09:55:20,536 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-09-17 09:55:20,537 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454179.8130924501 word corpus (62.0%% of prior 2346601)', 'datetime': '2023-09-17T09:55:20.537285', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-17 09:55:20,656 : INFO : estimated required memory for 11477 words and 1400 dimensions: 134280900 bytes\n",
      "2023-09-17 09:55:20,657 : INFO : resetting layer weights\n",
      "2023-09-17 09:55:20,730 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-17T09:55:20.730761', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-09-17 09:55:20,731 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 11477 vocabulary and 1400 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-09-17T09:55:20.731764', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:55:21,765 : INFO : EPOCH 0 - PROGRESS: at 16.46% examples, 360602 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:22,786 : INFO : EPOCH 0 - PROGRESS: at 45.09% examples, 378973 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:23,794 : INFO : EPOCH 0 - PROGRESS: at 78.19% examples, 389252 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:24,448 : INFO : EPOCH 0: training on 2416409 raw words (1453630 effective words) took 3.7s, 391769 effective words/s\n",
      "2023-09-17 09:55:25,463 : INFO : EPOCH 1 - PROGRESS: at 16.75% examples, 374391 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:26,474 : INFO : EPOCH 1 - PROGRESS: at 45.53% examples, 387105 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:27,489 : INFO : EPOCH 1 - PROGRESS: at 76.32% examples, 384119 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:28,245 : INFO : EPOCH 1: training on 2416409 raw words (1453829 effective words) took 3.8s, 383505 effective words/s\n",
      "2023-09-17 09:55:29,257 : INFO : EPOCH 2 - PROGRESS: at 16.75% examples, 375121 words/s, in_qsize 6, out_qsize 0\n",
      "2023-09-17 09:55:30,272 : INFO : EPOCH 2 - PROGRESS: at 45.97% examples, 389627 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:31,278 : INFO : EPOCH 2 - PROGRESS: at 79.59% examples, 398484 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:31,890 : INFO : EPOCH 2: training on 2416409 raw words (1454354 effective words) took 3.6s, 399563 effective words/s\n",
      "2023-09-17 09:55:32,909 : INFO : EPOCH 3 - PROGRESS: at 15.55% examples, 346872 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:33,912 : INFO : EPOCH 3 - PROGRESS: at 43.31% examples, 373714 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:34,915 : INFO : EPOCH 3 - PROGRESS: at 76.77% examples, 388464 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:35,600 : INFO : EPOCH 3: training on 2416409 raw words (1454504 effective words) took 3.7s, 392682 effective words/s\n",
      "2023-09-17 09:55:36,620 : INFO : EPOCH 4 - PROGRESS: at 16.46% examples, 366327 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:37,622 : INFO : EPOCH 4 - PROGRESS: at 45.53% examples, 388239 words/s, in_qsize 6, out_qsize 0\n",
      "2023-09-17 09:55:38,641 : INFO : EPOCH 4 - PROGRESS: at 78.19% examples, 392050 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-17 09:55:39,277 : INFO : EPOCH 4: training on 2416409 raw words (1454609 effective words) took 3.7s, 396237 effective words/s\n",
      "2023-09-17 09:55:39,278 : INFO : Word2Vec lifecycle event {'msg': 'training on 12082045 raw words (7270926 effective words) took 18.5s, 392049 effective words/s', 'datetime': '2023-09-17T09:55:39.278333', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-09-17 09:55:39,279 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=11477, vector_size=1400, alpha=0.025>', 'datetime': '2023-09-17T09:55:39.279331', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2023-09-17 09:55:39,288 : INFO : Word2Vec lifecycle event {'fname_or_handle': '1400features_word2vec', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-17T09:55:39.288308', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-09-17 09:55:39,289 : INFO : storing np array 'vectors' to 1400features_word2vec.wv.vectors.npy\n",
      "2023-09-17 09:55:39,850 : INFO : storing np array 'syn1neg' to 1400features_word2vec.syn1neg.npy\n",
      "2023-09-17 09:55:40,227 : INFO : not storing attribute cum_table\n",
      "2023-09-17 09:55:40,233 : INFO : saved 1400features_word2vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100features_word2vec', '200features_word2vec', '300features_word2vec', '400features_word2vec', '500features_word2vec', '600features_word2vec', '700features_word2vec', '800features_word2vec', '900features_word2vec', '1000features_word2vec', '1100features_word2vec', '1200features_word2vec', '1300features_word2vec', '1400features_word2vec']\n"
     ]
    }
   ],
   "source": [
    "print( \"Creating the word2vec of words...\\n\")\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)\n",
    "name = []\n",
    "from gensim.models import word2vec\n",
    "# num_features = 100    # Word vector dimensionality                      \n",
    "# min_word_count = 4   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 5          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "for i in tqdm_notebook(range(100, 1500, 100)):\n",
    "    model = word2vec.Word2Vec(sentences, \n",
    "#                               workers = num_workers, \n",
    "                              vector_size = i, \n",
    "#                               min_count = min_word_count,\n",
    "#                               window = context, \n",
    "#                               sample = downsampling\n",
    "                             )\n",
    "    model_name = str(i) + \"features_word2vec\"\n",
    "    model.save(model_name)\n",
    "    name.append(model_name)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9073f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    #index2word_set = set(model.wv.index2word)\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec, model.wv[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        if counter%1000 == 0:\n",
    "            print(\"Review %d of %d\" % (counter, len(reviews)))\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "440865a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016955137252807617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 14,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935c1784924e446094e72cd757865786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:55:40,658 : INFO : loading Word2Vec object from 100features_word2vec\n",
      "2023-09-17 09:55:40,677 : INFO : loading wv recursively from 100features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 09:55:40,680 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 09:55:40,790 : INFO : Word2Vec lifecycle event {'fname': '100features_word2vec', 'datetime': '2023-09-17T09:55:40.790981', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:56:55,052 : INFO : loading Word2Vec object from 200features_word2vec\n",
      "2023-09-17 09:56:55,072 : INFO : loading wv recursively from 200features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 09:56:55,074 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 09:56:55,182 : INFO : Word2Vec lifecycle event {'fname': '200features_word2vec', 'datetime': '2023-09-17T09:56:55.182286', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:58:15,237 : INFO : loading Word2Vec object from 300features_word2vec\n",
      "2023-09-17 09:58:15,263 : INFO : loading wv recursively from 300features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 09:58:15,264 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 09:58:15,372 : INFO : Word2Vec lifecycle event {'fname': '300features_word2vec', 'datetime': '2023-09-17T09:58:15.372835', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 09:59:41,942 : INFO : loading Word2Vec object from 400features_word2vec\n",
      "2023-09-17 09:59:42,033 : INFO : loading wv recursively from 400features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 09:59:42,034 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 09:59:42,148 : INFO : Word2Vec lifecycle event {'fname': '400features_word2vec', 'datetime': '2023-09-17T09:59:42.148157', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 10:01:21,178 : INFO : loading Word2Vec object from 500features_word2vec\n",
      "2023-09-17 10:01:21,216 : INFO : loading wv recursively from 500features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 10:01:21,218 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 10:01:21,332 : INFO : Word2Vec lifecycle event {'fname': '500features_word2vec', 'datetime': '2023-09-17T10:01:21.332758', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 10:03:07,206 : INFO : loading Word2Vec object from 600features_word2vec\n",
      "2023-09-17 10:03:07,253 : INFO : loading wv recursively from 600features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 10:03:07,254 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 10:03:07,365 : INFO : Word2Vec lifecycle event {'fname': '600features_word2vec', 'datetime': '2023-09-17T10:03:07.365381', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 10:05:02,295 : INFO : loading Word2Vec object from 700features_word2vec\n",
      "2023-09-17 10:05:02,344 : INFO : loading wv recursively from 700features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 10:05:02,345 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 10:05:02,459 : INFO : Word2Vec lifecycle event {'fname': '700features_word2vec', 'datetime': '2023-09-17T10:05:02.459303', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 10:07:05,779 : INFO : loading Word2Vec object from 800features_word2vec\n",
      "2023-09-17 10:07:05,839 : INFO : loading wv recursively from 800features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 10:07:05,840 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 10:07:05,978 : INFO : Word2Vec lifecycle event {'fname': '800features_word2vec', 'datetime': '2023-09-17T10:07:05.978864', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 10:09:17,889 : INFO : loading Word2Vec object from 900features_word2vec\n",
      "2023-09-17 10:09:17,958 : INFO : loading wv recursively from 900features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 10:09:17,960 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 10:09:18,079 : INFO : Word2Vec lifecycle event {'fname': '900features_word2vec', 'datetime': '2023-09-17T10:09:18.079642', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 10:11:39,930 : INFO : loading Word2Vec object from 1000features_word2vec\n",
      "2023-09-17 10:11:39,948 : INFO : loading wv recursively from 1000features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 10:11:39,950 : INFO : loading vectors from 1000features_word2vec.wv.vectors.npy with mmap=None\n",
      "2023-09-17 10:11:40,050 : INFO : loading syn1neg from 1000features_word2vec.syn1neg.npy with mmap=None\n",
      "2023-09-17 10:11:40,073 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 10:11:40,187 : INFO : Word2Vec lifecycle event {'fname': '1000features_word2vec', 'datetime': '2023-09-17T10:11:40.187266', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 10:14:15,645 : INFO : loading Word2Vec object from 1100features_word2vec\n",
      "2023-09-17 10:14:15,659 : INFO : loading wv recursively from 1100features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 10:14:15,660 : INFO : loading vectors from 1100features_word2vec.wv.vectors.npy with mmap=None\n",
      "2023-09-17 10:14:15,686 : INFO : loading syn1neg from 1100features_word2vec.syn1neg.npy with mmap=None\n",
      "2023-09-17 10:14:15,710 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 10:14:15,830 : INFO : Word2Vec lifecycle event {'fname': '1100features_word2vec', 'datetime': '2023-09-17T10:14:15.830515', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 10:16:54,548 : INFO : loading Word2Vec object from 1200features_word2vec\n",
      "2023-09-17 10:16:54,562 : INFO : loading wv recursively from 1200features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 10:16:54,563 : INFO : loading vectors from 1200features_word2vec.wv.vectors.npy with mmap=None\n",
      "2023-09-17 10:16:54,604 : INFO : loading syn1neg from 1200features_word2vec.syn1neg.npy with mmap=None\n",
      "2023-09-17 10:16:54,628 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 10:16:54,742 : INFO : Word2Vec lifecycle event {'fname': '1200features_word2vec', 'datetime': '2023-09-17T10:16:54.742724', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 10:19:41,882 : INFO : loading Word2Vec object from 1300features_word2vec\n",
      "2023-09-17 10:19:42,103 : INFO : loading wv recursively from 1300features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 10:19:42,104 : INFO : loading vectors from 1300features_word2vec.wv.vectors.npy with mmap=None\n",
      "2023-09-17 10:19:42,133 : INFO : loading syn1neg from 1300features_word2vec.syn1neg.npy with mmap=None\n",
      "2023-09-17 10:19:42,161 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 10:19:42,277 : INFO : Word2Vec lifecycle event {'fname': '1300features_word2vec', 'datetime': '2023-09-17T10:19:42.277489', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 10:22:33,916 : INFO : loading Word2Vec object from 1400features_word2vec\n",
      "2023-09-17 10:22:33,965 : INFO : loading wv recursively from 1400features_word2vec.wv.* with mmap=None\n",
      "2023-09-17 10:22:33,966 : INFO : loading vectors from 1400features_word2vec.wv.vectors.npy with mmap=None\n",
      "2023-09-17 10:22:34,524 : INFO : loading syn1neg from 1400features_word2vec.syn1neg.npy with mmap=None\n",
      "2023-09-17 10:22:34,933 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-17 10:22:35,050 : INFO : Word2Vec lifecycle event {'fname': '1400features_word2vec', 'datetime': '2023-09-17T10:22:35.050348', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 72550\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n",
      "['data_w2v_100.csv', 'data_w2v_200.csv', 'data_w2v_300.csv', 'data_w2v_400.csv', 'data_w2v_500.csv', 'data_w2v_600.csv', 'data_w2v_700.csv', 'data_w2v_800.csv', 'data_w2v_900.csv', 'data_w2v_1000.csv', 'data_w2v_1100.csv', 'data_w2v_1200.csv', 'data_w2v_1300.csv', 'data_w2v_1400.csv']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "ii = []\n",
    "for i in tqdm_notebook(range(100, 1500, 100)):\n",
    "    data = pd.read_csv(\"data_txt.csv\")\n",
    "    model_n = str(i) + \"features_word2vec\"\n",
    "    model = Word2Vec.load(model_n)\n",
    "    clean_train_reviews = []\n",
    "    for review in data[\"summary\"]:\n",
    "        clean_train_reviews.append( review_to_wordlist( review, remove_stopwords=True ))\n",
    "    trainDataVecs = getAvgFeatureVecs( clean_train_reviews, model, i )\n",
    "    \n",
    "    column_summary = []\n",
    "    for j in range(trainDataVecs.shape[1]):\n",
    "        col = \"summary_\" + str(j)\n",
    "        column_summary.append(col)\n",
    "    data_summary = pd.DataFrame(trainDataVecs, columns=column_summary)\n",
    "    data = pd.concat([data, data_summary], axis=1, ignore_index=False)\n",
    "    data.drop(columns=['summary'], axis=1, inplace=True)\n",
    "    data_n = \"data_w2v_\" + str(i) + \".csv\"\n",
    "    data.to_csv(data_n, index=False, encoding='utf_8_sig')\n",
    "    ii.append(data_n)\n",
    "\n",
    "print(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b245863b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           city  latitude  longitude                 attacktype1_txt  \\\n",
      "0      0.181904  0.681564   0.204755                   Armed Assault   \n",
      "1      0.688351  0.688223   0.106546               Bombing/Explosion   \n",
      "2      0.558561  0.732945   0.204053  Facility/Infrastructure Attack   \n",
      "3      0.558561  0.732914   0.204130  Facility/Infrastructure Attack   \n",
      "4      0.249211  0.704869   0.158102  Facility/Infrastructure Attack   \n",
      "...         ...       ...        ...                             ...   \n",
      "72545  0.009873  0.477141   0.603580               Bombing/Explosion   \n",
      "72546  0.142187  0.611361   0.713903  Facility/Infrastructure Attack   \n",
      "72547  0.787440  0.497927   0.597584               Bombing/Explosion   \n",
      "72548  0.420521  0.660566   0.675203                   Armed Assault   \n",
      "72549  0.974123  0.687351   0.180508                   Assassination   \n",
      "\n",
      "                                        targsubtype1_txt  \\\n",
      "0        Police Building (headquarters, station, school)   \n",
      "1                                            Electricity   \n",
      "2                    Military Recruiting Station/Academy   \n",
      "3                    Government Building/Facility/Office   \n",
      "4                    Military Recruiting Station/Academy   \n",
      "...                                                  ...   \n",
      "72545                                  International NGO   \n",
      "72546  Government Personnel (excluding police, military)   \n",
      "72547                          House/Apartment/Residence   \n",
      "72548                                          Protester   \n",
      "72549                                          Personnel   \n",
      "\n",
      "                                weapsubtype1_txt      date  risk  \n",
      "0                               Unknown Gun Type  0.500000     1  \n",
      "1                         Unknown Explosive Type  0.666667     1  \n",
      "2                   Molotov Cocktail/Petrol Bomb  0.666667     1  \n",
      "3                            Gasoline or Alcohol  0.833333     1  \n",
      "4                   Molotov Cocktail/Petrol Bomb  0.166667     1  \n",
      "...                                          ...       ...   ...  \n",
      "72545                     Unknown Explosive Type  0.500000     1  \n",
      "72546                        Gasoline or Alcohol  0.500000     1  \n",
      "72547  Projectile (rockets, mortars, RPGs, etc.)  0.500000     1  \n",
      "72548                           Unknown Gun Type  0.500000     2  \n",
      "72549                                    Handgun  0.500000     2  \n",
      "\n",
      "[72550 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_txt.csv\")\n",
    "data.drop(columns=[\"summary\"], axis=1, inplace=True)\n",
    "print(data)\n",
    "data.to_csv('data_w2v_0.csv', index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c791d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_func(solution, solution_idx):\n",
    "    # 从解决方案中提取超参数\n",
    "    learning_rate = solution[0]\n",
    "    min_child_samples = int(solution[1])\n",
    "    max_depth = int(solution[2])\n",
    "    num_leaves = int(solution[3])\n",
    "    colsample_bytree = (solution[4])\n",
    "    reg_alpha = solution[5]\n",
    "    reg_lambda = solution[6]\n",
    "    \n",
    "    print(learning_rate, min_child_samples, max_depth, num_leaves,\n",
    "          colsample_bytree, reg_alpha, reg_lambda)\n",
    "    # 定义LightBGM的函数\n",
    "    LGB = lgb.LGBMClassifier(learning_rate=learning_rate, # 学习率\n",
    "                             min_child_samples=min_child_samples,\n",
    "                             max_depth=max_depth, # 树的最大深度\n",
    "                             num_leaves=num_leaves, \n",
    "                             colsample_bytree=colsample_bytree,\n",
    "                             reg_alpha=reg_alpha,\n",
    "                             reg_lambda=reg_lambda,\n",
    "                             random_state=0 # 随机种子\n",
    "                            )\n",
    "\n",
    "    # 利用训练数据训练LightLGB分类器\n",
    "    LGB.fit(X_train, y_train, categorical_feature=category_col)\n",
    "    # 对测试数据进行预测\n",
    "#     y_pred_prob = LGB.predict_proba(X_test)\n",
    "    y_pred = LGB.predict(X_test)\n",
    "    # 计算准确率\n",
    "#     acc = accuracy_score(y_test, y_pred)\n",
    "#     f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "#     precision = precision_score(y_test, y_pred, average='weighted')\n",
    "#     roc_auc = roc_auc_score(y_one_hot, y_pred_prob, multi_class=\"ovo\", average=\"weighted\")\n",
    "#     print('当前准确率：', precision)\n",
    "    # 返回适应函数分数（准确性）\n",
    "    fitness = recall\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64164c97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016988515853881836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 15,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4868c8e79a646e098d9efc830d0cc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6610613370089593\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6516884906960717\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6485182632667126\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6573397656788422\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.6609235010337698\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.6566505858028946\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6606478290833908\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.6526533425223984\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6657477601654032\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6514128187456927\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7223983459682978\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7254307374224672\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7222605099931082\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7314955203308063\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7345279117849759\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.729290144727774\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7302549965541006\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7283252929014473\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7284631288766368\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7221226740179186\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7286009648518263\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7230875258442453\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7254307374224672\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7294279807029634\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7386629910406616\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7317711922811854\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7371467953135769\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7325982081323226\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 92.55966383] with fitness value 0.7376981392143349\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7270847691247415\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7301171605789111\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7246037215713301\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7287388008270158\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7357684355616816\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7371467953135769\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7251550654720882\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.732460372157133\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7345279117849759\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7372846312887664\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.729565816678153\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.729841488628532\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7276361130254997\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7243280496209511\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7338387319090283\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7356305995864921\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7291523087525844\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7354927636113026\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7337008959338387\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7334252239834597\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7277739490006891\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7301171605789111\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7254307374224672\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.729014472777395\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7343900758097863\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7379738111647139\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.729841488628532\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7381116471399035\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7343900758097863\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7399035148173674\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7337008959338387\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7375603032391455\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7331495520330806\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.729565816678153\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7411440385940731\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.732736044107512\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7317711922811854\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7378359751895245\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7359062715368712\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7392143349414197\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7310820124052377\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7272226050999311\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7346657477601654\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7255685733976568\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7381116471399035\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7415575465196417\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 43.75872113] with fitness value 0.7312198483804273\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7319090282563749\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7411440385940731\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7341144038594073\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7313576843556168\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7332873880082702\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 43.75872113] with fitness value 0.7299793246037216\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 92.55966383] with fitness value 0.7341144038594073\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7328738800827016\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7421088904203997\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7342522398345969\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7354927636113026\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7410062026188835\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7345279117849759\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7309441764300483\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7325982081323226\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7325982081323226\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.729014472777395\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7363197794624396\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7433494141971054\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7277739490006891\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7331495520330806\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7345279117849759\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7332873880082702\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7286009648518263\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7331495520330806\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7301171605789111\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7250172294968987\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7371467953135769\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7411440385940731\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7343900758097863\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7363197794624396\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7363197794624396\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7392143349414197\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7284631288766368\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7332873880082702\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7323225361819435\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7312198483804273\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7415575465196417\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7400413507925568\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7306685044796692\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7360441075120606\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 43.75872113] with fitness value 0.7309441764300483\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7332873880082702\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7317711922811854\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7330117160578911\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.732460372157133\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.729290144727774\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7385251550654721\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7389386629910406\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7331495520330806\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7371467953135769\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7425223983459683\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7381116471399035\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7328738800827016\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7337008959338387\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7330117160578911\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7313576843556168\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7394900068917988\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7397656788421778\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7319090282563749\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7349414197105445\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7383873190902825\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7345279117849759\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 56.80445611\n",
      " 43.75872113] with fitness value 0.7357684355616816\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7361819434872502\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.735354927636113\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7341144038594073\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 56.76390238  0.57600543 64.58941131\n",
      " 92.55966383] with fitness value 0.740868366643694\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7421088904203997\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7312198483804273\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7360441075120606\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7422467263955892\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7407305306685045\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7337008959338387\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "[0.6657477601654032, 0.7345279117849759, 0.7386629910406616, 0.7372846312887664, 0.7356305995864921, 0.7399035148173674, 0.7411440385940731, 0.7415575465196417, 0.7421088904203997, 0.7433494141971054, 0.7411440385940731, 0.7415575465196417, 0.7425223983459683, 0.7397656788421778, 0.7422467263955892] [0.5533253688880515, 0.5533253688880515, 0.892855270774259, 0.5533253688880515, 0.5533253688880515, 0.5533253688880515, 0.5533253688880515, 0.5533253688880515, 0.5533253688880515, 0.5533253688880515, 0.5533253688880515, 0.5533253688880515, 0.5533253688880515, 0.5533253688880515, 0.5533253688880515] [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37] [9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9] [80, 56, 80, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56] [0.7616746199103354, 0.4812893194050143, 0.7616746199103354, 0.4812893194050143, 0.4812893194050143, 0.4812893194050143, 0.4812893194050143, 0.4812893194050143, 0.4812893194050143, 0.4812893194050143, 0.4812893194050143, 0.4812893194050143, 0.4812893194050143, 0.4812893194050143, 0.4812893194050143] [64.58941130666561, 64.58941130666561, 56.80445610939323, 64.58941130666561, 64.58941130666561, 64.58941130666561, 64.58941130666561, 64.58941130666561, 64.58941130666561, 64.58941130666561, 64.58941130666561, 64.58941130666561, 64.58941130666561, 64.58941130666561, 64.58941130666561] [43.75872112626925, 43.75872112626925, 92.5596638292661, 43.75872112626925, 43.75872112626925, 43.75872112626925, 43.75872112626925, 43.75872112626925, 43.75872112626925, 43.75872112626925, 43.75872112626925, 43.75872112626925, 43.75872112626925, 43.75872112626925, 43.75872112626925]\n"
     ]
    }
   ],
   "source": [
    "import pygad\n",
    "\n",
    "max__ = []\n",
    "lr__ = []\n",
    "mcs__ = []\n",
    "md__ = []\n",
    "nl__ = []\n",
    "cb__ = []\n",
    "ra__ = []\n",
    "rl__ = []\n",
    "\n",
    "for i in tqdm_notebook(range(0, 1500, 100)):\n",
    "    name = \"data_w2v_\" + str(i) + '.csv'\n",
    "    data = pd.read_csv(name)\n",
    "    \n",
    "    max_ = {'max': 0, \n",
    "           'learning_rate': 0,\n",
    "           'min_child_samples': 0,              \n",
    "           'max_depth': 0,\n",
    "           'num_leaves': 0, \n",
    "           'colsample_bytree': 0,\n",
    "           'reg_alpha': 0,\n",
    "           'reg_lambda': 0}\n",
    "    \n",
    "    category_col = ['attacktype1_txt', 'targsubtype1_txt', 'weapsubtype1_txt']\n",
    "    data[category_col] = data[category_col].astype('category')\n",
    "    X = data.drop(columns=['risk'], axis=1)\n",
    "    y = data['risk']\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    splits = kf.split(X, y)\n",
    "    \n",
    "    for k, (train_indices, test_indices) in enumerate(splits):\n",
    "        print(\"第 %d 折\\n\" % (k + 1))\n",
    "        X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "        y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "        labels = [0, 1, 2, 3]\n",
    "        y_one_hot = label_binarize(y_test, classes=labels)\n",
    "        \n",
    "        param_list = [\n",
    "        {'low': 0.01, 'high': 1}, # learning_rate \n",
    "        {'low': 5, 'high': 50}, # min_child_samples\n",
    "        {'low': 1, 'high': 15}, # max_depth \n",
    "        {'low': 5, 'high':100}, #num_leaves \n",
    "        {'low': 0.1, 'high': 1}, #colsample_bytree\n",
    "        {'low': 0, 'high': 100}, # reg_alpha\n",
    "        {'low': 0, 'high': 100}, #reg_lambda\n",
    "        ]\n",
    "    \n",
    "        # 定义遗传算法\n",
    "        ga_instance = pygad.GA(num_generations=4, # 遗传算法的代数 \n",
    "                               num_parents_mating=2, # 每代选择交叉的父代数量 \n",
    "                               fitness_func=fitness_func, # 适应函数 \n",
    "        #                            initial_population=[20, 8],\n",
    "                               sol_per_pop=3, # 种群中的解决方案数量 \n",
    "                               num_genes=len(param_list), # 解决方案中的基因数量（即超参数数量） \n",
    "                               gene_type=float, # 基因类型（即超参数类型） \n",
    "                               gene_space=param_list, # 基因空间（即超参数范围） \n",
    "                               parent_selection_type='rws', # 父代选择类型 \n",
    "                               keep_parents=1, # 保留的父代数量 \n",
    "                               crossover_type='uniform', # 交叉类型 \n",
    "                               crossover_probability=0.6,\n",
    "                               mutation_type='random', # 变异类型 \n",
    "                               mutation_probability=0.01,\n",
    "        #                            mutation_percent_genes=10 # 变异基因百分比\n",
    "                               random_seed=0\n",
    "                              )\n",
    "        # 开始遗传算法\n",
    "        ga_instance.run()\n",
    "        \n",
    "        # 获取最优超参数组合\n",
    "        best_solution, best_fitness, best_solution_idx = ga_instance.best_solution()\n",
    "        best_learning_rate = best_solution[0] \n",
    "        best_min_child_samples = int(best_solution[1])\n",
    "        best_max_depth = int(best_solution[2])\n",
    "        best_num_leaves = int(best_solution[3])\n",
    "        best_colsample_bytree = (best_solution[4])\n",
    "        best_reg_alpha = best_solution[5]\n",
    "        best_reg_lambda = best_solution[6]\n",
    "\n",
    "        # 打印最佳解决方案和最佳适应值\n",
    "        print('Best solution is {solution} with fitness value {fitness}'.format(solution=best_solution, fitness=best_fitness)) \n",
    "        print('Best learning rate is {lr}'.format(lr=best_learning_rate)) \n",
    "        print('Best min child samples is {mcs}'.format(mcs=best_min_child_samples))\n",
    "        print('Best max depth is {md}'.format(md=best_max_depth)) \n",
    "        print('Best num leaves is {nl}'.format(nl=best_num_leaves))  \n",
    "        print('Best colsample bytree is {cb}'.format(cb=best_colsample_bytree))\n",
    "        print('Best reg_alpha is {al}'.format(al=best_reg_alpha))\n",
    "        print('Best reg_lambda is {la}'.format(la=best_reg_lambda))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        if best_fitness > max_['max']:\n",
    "            max_['max'] = best_fitness\n",
    "            max_['learning_rate'] = best_learning_rate \n",
    "            max_['min_child_samples'] = best_min_child_samples\n",
    "            max_['max_depth'] = best_max_depth\n",
    "            max_['num_leaves'] = best_num_leaves\n",
    "            max_['colsample_bytree'] = best_colsample_bytree\n",
    "            max_['reg_alpha'] = best_reg_alpha\n",
    "            max_['reg_lambda'] = best_reg_lambda\n",
    "            \n",
    "    max__.append(max_['max'])\n",
    "    lr__.append(max_['learning_rate'])\n",
    "    mcs__.append(max_['min_child_samples'])\n",
    "    md__.append(max_['max_depth'])\n",
    "    nl__.append(max_['num_leaves'])\n",
    "    cb__.append(max_['colsample_bytree'])\n",
    "    ra__.append(max_['reg_alpha'])\n",
    "    rl__.append(max_['reg_lambda'])\n",
    "        \n",
    "print(max__, lr__, mcs__, md__, nl__, cb__, ra__, rl__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eebefffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6657477601654032, 0.7345279117849759, 0.7386629910406616, 0.7372846312887664, 0.7356305995864921, 0.7399035148173674, 0.7411440385940731, 0.7415575465196417, 0.7421088904203997, 0.7433494141971054, 0.7411440385940731, 0.7415575465196417, 0.7425223983459683, 0.7397656788421778, 0.7422467263955892]\n"
     ]
    }
   ],
   "source": [
    "print(max__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf381f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.028949260711669922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 15,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f981aeadcb1e46f1a890c4c7acfee02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 85.8203385658022%\n",
      " ACC: 66.10613370089592%\n",
      " F1: 65.38838699531145%\n",
      " RECALL: 66.10613370089592%\n",
      " PRECISION: 65.2823793900078%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 85.68169589008116%\n",
      " ACC: 65.16884906960718%\n",
      " F1: 64.51924163171235%\n",
      " RECALL: 65.16884906960718%\n",
      " PRECISION: 64.56169792549115%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 86.02516852805526%\n",
      " ACC: 65.26533425223984%\n",
      " F1: 64.62498723706126%\n",
      " RECALL: 65.26533425223984%\n",
      " PRECISION: 64.74274909751783%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 86.14994448721146%\n",
      " ACC: 65.73397656788423%\n",
      " F1: 65.12605096813078%\n",
      " RECALL: 65.73397656788423%\n",
      " PRECISION: 65.2392289353695%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 86.4614149902275%\n",
      " ACC: 65.70640937284631%\n",
      " F1: 64.8898762391123%\n",
      " RECALL: 65.70640937284631%\n",
      " PRECISION: 64.8517698610826%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 86.00557159858087%\n",
      " ACC: 65.48587181254307%\n",
      " F1: 64.81125495871167%\n",
      " RECALL: 65.48587181254307%\n",
      " PRECISION: 64.79430502842466%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 86.22343578054782%\n",
      " ACC: 65.78911095796003%\n",
      " F1: 65.22985644503713%\n",
      " RECALL: 65.78911095796003%\n",
      " PRECISION: 65.25464717722605%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 85.88527826972339%\n",
      " ACC: 65.77532736044107%\n",
      " F1: 65.15798637900293%\n",
      " RECALL: 65.77532736044107%\n",
      " PRECISION: 65.28221803933849%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 86.28977128611953%\n",
      " ACC: 66.57477601654031%\n",
      " F1: 65.97521410754054%\n",
      " RECALL: 66.57477601654031%\n",
      " PRECISION: 66.00149076652137%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 85.60269241860755%\n",
      " ACC: 65.14128187456927%\n",
      " F1: 64.42599346118398%\n",
      " RECALL: 65.14128187456927%\n",
      " PRECISION: 64.63091059960438%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.09122389483659%\n",
      " ACC: 72.23983459682978%\n",
      " F1: 72.09020820797016%\n",
      " RECALL: 72.23983459682978%\n",
      " PRECISION: 72.18728398676215%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.08462072691697%\n",
      " ACC: 72.33631977946244%\n",
      " F1: 72.16324068291793%\n",
      " RECALL: 72.33631977946244%\n",
      " PRECISION: 72.3170230098555%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.13941999377282%\n",
      " ACC: 72.22605099931081%\n",
      " F1: 72.0798542365903%\n",
      " RECALL: 72.22605099931081%\n",
      " PRECISION: 72.30627437266571%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 90.87535672230884%\n",
      " ACC: 73.14955203308064%\n",
      " F1: 73.01532032750893%\n",
      " RECALL: 73.14955203308064%\n",
      " PRECISION: 73.16647405806678%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 90.81316568372269%\n",
      " ACC: 73.45279117849759%\n",
      " F1: 73.2843620195024%\n",
      " RECALL: 73.45279117849759%\n",
      " PRECISION: 73.37110414100985%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.13904024204604%\n",
      " ACC: 72.9290144727774%\n",
      " F1: 72.7533888051127%\n",
      " RECALL: 72.9290144727774%\n",
      " PRECISION: 73.00645355187328%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.59354216216248%\n",
      " ACC: 73.02549965541006%\n",
      " F1: 72.88061927006953%\n",
      " RECALL: 73.02549965541006%\n",
      " PRECISION: 73.00289206003579%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.31059549795594%\n",
      " ACC: 72.83252929014473%\n",
      " F1: 72.67926141433769%\n",
      " RECALL: 72.83252929014473%\n",
      " PRECISION: 73.00158300731428%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.39885668041741%\n",
      " ACC: 72.84631288766367%\n",
      " F1: 72.72502851269975%\n",
      " RECALL: 72.84631288766367%\n",
      " PRECISION: 72.92236316939974%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.19143742622929%\n",
      " ACC: 72.21226740179186%\n",
      " F1: 72.05395422891702%\n",
      " RECALL: 72.21226740179186%\n",
      " PRECISION: 72.23214963391527%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.0912790167116%\n",
      " ACC: 72.33631977946244%\n",
      " F1: 72.26931407758124%\n",
      " RECALL: 72.33631977946244%\n",
      " PRECISION: 72.27887335081915%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 89.99057853744841%\n",
      " ACC: 72.10199862164025%\n",
      " F1: 71.94780007418404%\n",
      " RECALL: 72.10199862164025%\n",
      " PRECISION: 72.06876901474301%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.16384322830753%\n",
      " ACC: 71.96416264645073%\n",
      " F1: 71.8190551980078%\n",
      " RECALL: 71.96416264645073%\n",
      " PRECISION: 71.91708793584483%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 90.50615392253178%\n",
      " ACC: 73.46657477601653%\n",
      " F1: 73.35552321536865%\n",
      " RECALL: 73.46657477601653%\n",
      " PRECISION: 73.40080078676682%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 90.69912237667215%\n",
      " ACC: 73.86629910406616%\n",
      " F1: 73.69512831868708%\n",
      " RECALL: 73.86629910406616%\n",
      " PRECISION: 73.79240145319517%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.2028153765368%\n",
      " ACC: 72.46037215713301%\n",
      " F1: 72.2898985031828%\n",
      " RECALL: 72.46037215713301%\n",
      " PRECISION: 72.41702302555547%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.28654752985948%\n",
      " ACC: 72.54307374224672%\n",
      " F1: 72.47185493456787%\n",
      " RECALL: 72.54307374224672%\n",
      " PRECISION: 72.52967196206194%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.39945622907712%\n",
      " ACC: 72.10199862164025%\n",
      " F1: 71.96548456946059%\n",
      " RECALL: 72.10199862164025%\n",
      " PRECISION: 72.15148381256448%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.46302701453058%\n",
      " ACC: 73.32873880082703%\n",
      " F1: 73.22930860049433%\n",
      " RECALL: 73.32873880082703%\n",
      " PRECISION: 73.38500492129047%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.08163108282619%\n",
      " ACC: 72.12956581667815%\n",
      " F1: 71.98951214263818%\n",
      " RECALL: 72.12956581667815%\n",
      " PRECISION: 72.07945518535477%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.34549561839675%\n",
      " ACC: 73.0117160578911%\n",
      " F1: 72.90053345131496%\n",
      " RECALL: 73.0117160578911%\n",
      " PRECISION: 72.9538426862079%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.28702876897535%\n",
      " ACC: 72.36388697450035%\n",
      " F1: 72.17785989562668%\n",
      " RECALL: 72.36388697450035%\n",
      " PRECISION: 72.29001272485746%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.53873732362588%\n",
      " ACC: 72.87388008270158%\n",
      " F1: 72.73339976694058%\n",
      " RECALL: 72.87388008270158%\n",
      " PRECISION: 72.95941749961891%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 90.97153038467086%\n",
      " ACC: 73.57684355616816%\n",
      " F1: 73.45267308828605%\n",
      " RECALL: 73.57684355616816%\n",
      " PRECISION: 73.56349505002765%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 90.93614764466601%\n",
      " ACC: 73.71467953135769%\n",
      " F1: 73.5225556750955%\n",
      " RECALL: 73.71467953135769%\n",
      " PRECISION: 73.69379294076013%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.40435907420483%\n",
      " ACC: 72.51550654720882%\n",
      " F1: 72.32763692374313%\n",
      " RECALL: 72.51550654720882%\n",
      " PRECISION: 72.56672760617914%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.6022447021767%\n",
      " ACC: 73.2460372157133%\n",
      " F1: 73.09406894689198%\n",
      " RECALL: 73.2460372157133%\n",
      " PRECISION: 73.21731011810311%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.59169960683795%\n",
      " ACC: 73.45279117849759%\n",
      " F1: 73.30158681864408%\n",
      " RECALL: 73.45279117849759%\n",
      " PRECISION: 73.50118036959292%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.8171997060891%\n",
      " ACC: 73.72846312887664%\n",
      " F1: 73.6339810575329%\n",
      " RECALL: 73.72846312887664%\n",
      " PRECISION: 73.77657485835823%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.4209342428597%\n",
      " ACC: 72.9565816678153%\n",
      " F1: 72.86186495866363%\n",
      " RECALL: 72.9565816678153%\n",
      " PRECISION: 73.01711931910604%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.35179971095376%\n",
      " ACC: 72.9841488628532%\n",
      " F1: 72.86241927112484%\n",
      " RECALL: 72.9841488628532%\n",
      " PRECISION: 72.91562118417339%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.35644061756487%\n",
      " ACC: 72.62577532736044%\n",
      " F1: 72.44614637447052%\n",
      " RECALL: 72.62577532736044%\n",
      " PRECISION: 72.57237383918635%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.38667194645235%\n",
      " ACC: 72.4328049620951%\n",
      " F1: 72.27052030169578%\n",
      " RECALL: 72.4328049620951%\n",
      " PRECISION: 72.42837720485493%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 90.78944168210954%\n",
      " ACC: 73.32873880082703%\n",
      " F1: 73.21747869730825%\n",
      " RECALL: 73.32873880082703%\n",
      " PRECISION: 73.32626448058171%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.18852664277651%\n",
      " ACC: 73.56305995864922%\n",
      " F1: 73.31306389453216%\n",
      " RECALL: 73.56305995864922%\n",
      " PRECISION: 73.46379174526983%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.32054768058629%\n",
      " ACC: 72.57064093728464%\n",
      " F1: 72.4231208866558%\n",
      " RECALL: 72.57064093728464%\n",
      " PRECISION: 72.62771333237625%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.77085657769538%\n",
      " ACC: 73.54927636113025%\n",
      " F1: 73.43079442188831%\n",
      " RECALL: 73.54927636113025%\n",
      " PRECISION: 73.50714952870699%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.72288433178059%\n",
      " ACC: 73.37008959338387%\n",
      " F1: 73.23238403401837%\n",
      " RECALL: 73.37008959338387%\n",
      " PRECISION: 73.43969925441395%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.66894960970428%\n",
      " ACC: 73.34252239834596%\n",
      " F1: 73.26094194390261%\n",
      " RECALL: 73.34252239834596%\n",
      " PRECISION: 73.44721106559751%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.53664635703814%\n",
      " ACC: 72.77739490006891%\n",
      " F1: 72.67619243677841%\n",
      " RECALL: 72.77739490006891%\n",
      " PRECISION: 72.87464857697596%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.38688101673729%\n",
      " ACC: 73.0117160578911%\n",
      " F1: 72.85283222745812%\n",
      " RECALL: 73.0117160578911%\n",
      " PRECISION: 72.9536945240314%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.42154164839182%\n",
      " ACC: 72.33631977946244%\n",
      " F1: 72.11409542105778%\n",
      " RECALL: 72.33631977946244%\n",
      " PRECISION: 72.33980282196647%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.66114480892728%\n",
      " ACC: 72.90144727773949%\n",
      " F1: 72.75838623539846%\n",
      " RECALL: 72.90144727773949%\n",
      " PRECISION: 73.02213905235003%\n",
      "第 4 折\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold 4 | \n",
      " AUC_ROC: 91.00702589021222%\n",
      " ACC: 73.43900758097863%\n",
      " F1: 73.28765063551253%\n",
      " RECALL: 73.43900758097863%\n",
      " PRECISION: 73.50139945028232%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.28188150919668%\n",
      " ACC: 73.7698139214335%\n",
      " F1: 73.54051022099675%\n",
      " RECALL: 73.7698139214335%\n",
      " PRECISION: 73.73054121314289%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.6015121165004%\n",
      " ACC: 72.83252929014473%\n",
      " F1: 72.6471404542872%\n",
      " RECALL: 72.83252929014473%\n",
      " PRECISION: 72.87422052251544%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 91.03657676305012%\n",
      " ACC: 73.81116471399035%\n",
      " F1: 73.67294557532799%\n",
      " RECALL: 73.81116471399035%\n",
      " PRECISION: 73.8360840447231%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.80552890648417%\n",
      " ACC: 73.43900758097863%\n",
      " F1: 73.349399573692%\n",
      " RECALL: 73.43900758097863%\n",
      " PRECISION: 73.5543193809164%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.83720676649449%\n",
      " ACC: 73.99035148173674%\n",
      " F1: 73.89205680317056%\n",
      " RECALL: 73.99035148173674%\n",
      " PRECISION: 74.06184330186498%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.6836130469816%\n",
      " ACC: 73.37008959338387%\n",
      " F1: 73.20600838471317%\n",
      " RECALL: 73.37008959338387%\n",
      " PRECISION: 73.38910493375288%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.6139016765571%\n",
      " ACC: 73.75603032391454%\n",
      " F1: 73.62225733049789%\n",
      " RECALL: 73.75603032391454%\n",
      " PRECISION: 73.69702728411546%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.57285656907142%\n",
      " ACC: 73.31495520330806%\n",
      " F1: 73.155158579642%\n",
      " RECALL: 73.31495520330806%\n",
      " PRECISION: 73.34559771503268%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.68762406133824%\n",
      " ACC: 72.9565816678153%\n",
      " F1: 72.8237962363157%\n",
      " RECALL: 72.9565816678153%\n",
      " PRECISION: 73.01475124305743%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.20669771007243%\n",
      " ACC: 74.1144038594073%\n",
      " F1: 74.00085173898717%\n",
      " RECALL: 74.1144038594073%\n",
      " PRECISION: 74.1436041132402%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.00163099856692%\n",
      " ACC: 73.2736044107512%\n",
      " F1: 73.06546845140086%\n",
      " RECALL: 73.2736044107512%\n",
      " PRECISION: 73.22268453117852%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.57966484245733%\n",
      " ACC: 73.17711922811854%\n",
      " F1: 72.97554319772065%\n",
      " RECALL: 73.17711922811854%\n",
      " PRECISION: 73.20277351988086%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.85900026980643%\n",
      " ACC: 73.37008959338387%\n",
      " F1: 73.24438325651084%\n",
      " RECALL: 73.37008959338387%\n",
      " PRECISION: 73.366100078141%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.70313750834585%\n",
      " ACC: 73.59062715368711%\n",
      " F1: 73.49570136427025%\n",
      " RECALL: 73.59062715368711%\n",
      " PRECISION: 73.74565082787467%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.75343166341344%\n",
      " ACC: 73.92143349414198%\n",
      " F1: 73.82915141476151%\n",
      " RECALL: 73.92143349414198%\n",
      " PRECISION: 74.0025735071154%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.40618299676385%\n",
      " ACC: 73.10820124052377%\n",
      " F1: 72.98332426336593%\n",
      " RECALL: 73.10820124052377%\n",
      " PRECISION: 73.22066018167003%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.49564893574255%\n",
      " ACC: 72.70847691247415%\n",
      " F1: 72.58474640405274%\n",
      " RECALL: 72.70847691247415%\n",
      " PRECISION: 72.64943544153408%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.58220262537178%\n",
      " ACC: 73.13576843556167%\n",
      " F1: 72.95200302329062%\n",
      " RECALL: 73.13576843556167%\n",
      " PRECISION: 73.06272415513911%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.64673048723908%\n",
      " ACC: 72.55685733976568%\n",
      " F1: 72.42206006778008%\n",
      " RECALL: 72.55685733976568%\n",
      " PRECISION: 72.6042473485953%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 90.99973376834666%\n",
      " ACC: 73.81116471399035%\n",
      " F1: 73.69448768440066%\n",
      " RECALL: 73.81116471399035%\n",
      " PRECISION: 73.78699268582824%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.19204493692993%\n",
      " ACC: 74.15575465196417%\n",
      " F1: 73.9719281570233%\n",
      " RECALL: 74.15575465196417%\n",
      " PRECISION: 74.07965709498792%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.60623780791731%\n",
      " ACC: 72.9290144727774%\n",
      " F1: 72.77553571776491%\n",
      " RECALL: 72.9290144727774%\n",
      " PRECISION: 72.9657865442809%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.92924796699414%\n",
      " ACC: 73.1909028256375%\n",
      " F1: 73.0717787856119%\n",
      " RECALL: 73.1909028256375%\n",
      " PRECISION: 73.17684024282448%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.72330868440204%\n",
      " ACC: 74.1144038594073%\n",
      " F1: 74.00950112342444%\n",
      " RECALL: 74.1144038594073%\n",
      " PRECISION: 74.23972838936838%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.83649218330892%\n",
      " ACC: 73.41144038594074%\n",
      " F1: 73.34700446433749%\n",
      " RECALL: 73.41144038594074%\n",
      " PRECISION: 73.46281837040519%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.61364641466051%\n",
      " ACC: 73.13576843556167%\n",
      " F1: 73.01649228365628%\n",
      " RECALL: 73.13576843556167%\n",
      " PRECISION: 73.21104809080664%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.62341294816963%\n",
      " ACC: 73.02549965541006%\n",
      " F1: 72.90967920968421%\n",
      " RECALL: 73.02549965541006%\n",
      " PRECISION: 72.99845164011343%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.52764530125371%\n",
      " ACC: 72.77739490006891%\n",
      " F1: 72.62816842969812%\n",
      " RECALL: 72.77739490006891%\n",
      " PRECISION: 72.7383246333418%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.65731384183051%\n",
      " ACC: 72.62577532736044%\n",
      " F1: 72.47116912083392%\n",
      " RECALL: 72.62577532736044%\n",
      " PRECISION: 72.73348843443215%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.05190908377098%\n",
      " ACC: 73.28738800827016%\n",
      " F1: 73.15393303767065%\n",
      " RECALL: 73.28738800827016%\n",
      " PRECISION: 73.28573405001619%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.07023450891145%\n",
      " ACC: 74.21088904203998%\n",
      " F1: 73.98986750709021%\n",
      " RECALL: 74.21088904203998%\n",
      " PRECISION: 74.18712565954213%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.66209745382608%\n",
      " ACC: 73.42522398345969%\n",
      " F1: 73.22667824471722%\n",
      " RECALL: 73.42522398345969%\n",
      " PRECISION: 73.53715427928589%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.96034206528839%\n",
      " ACC: 73.54927636113025%\n",
      " F1: 73.4238482412955%\n",
      " RECALL: 73.54927636113025%\n",
      " PRECISION: 73.53831514422751%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.84194121101902%\n",
      " ACC: 74.10062026188835%\n",
      " F1: 73.99308416260743%\n",
      " RECALL: 74.10062026188835%\n",
      " PRECISION: 74.15458491615486%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.66833929586736%\n",
      " ACC: 73.45279117849759%\n",
      " F1: 73.36730315917805%\n",
      " RECALL: 73.45279117849759%\n",
      " PRECISION: 73.52339928551574%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.56124076432536%\n",
      " ACC: 72.50172294968988%\n",
      " F1: 72.38269284056071%\n",
      " RECALL: 72.50172294968988%\n",
      " PRECISION: 72.5307810935496%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.74403684812326%\n",
      " ACC: 73.25982081323225%\n",
      " F1: 73.14488949959289%\n",
      " RECALL: 73.25982081323225%\n",
      " PRECISION: 73.23325763935323%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.49391551113834%\n",
      " ACC: 73.25982081323225%\n",
      " F1: 73.10642125274754%\n",
      " RECALL: 73.25982081323225%\n",
      " PRECISION: 73.23369939728211%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.57367502291896%\n",
      " ACC: 72.90144727773949%\n",
      " F1: 72.74618923040329%\n",
      " RECALL: 72.90144727773949%\n",
      " PRECISION: 73.00088052485623%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 90.9542995743965%\n",
      " ACC: 73.63197794624396%\n",
      " F1: 73.52131066377652%\n",
      " RECALL: 73.63197794624396%\n",
      " PRECISION: 73.64530792101097%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.1552488054316%\n",
      " ACC: 74.33494141971055%\n",
      " F1: 74.13859522738865%\n",
      " RECALL: 74.33494141971055%\n",
      " PRECISION: 74.2831379696735%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.4915998930932%\n",
      " ACC: 72.77739490006891%\n",
      " F1: 72.61382514302842%\n",
      " RECALL: 72.77739490006891%\n",
      " PRECISION: 72.82124666620494%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.78008331250969%\n",
      " ACC: 73.30117160578911%\n",
      " F1: 73.16563858475973%\n",
      " RECALL: 73.30117160578911%\n",
      " PRECISION: 73.29531844956541%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.7817621797585%\n",
      " ACC: 73.45279117849759%\n",
      " F1: 73.32116597144879%\n",
      " RECALL: 73.45279117849759%\n",
      " PRECISION: 73.51459968063772%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.69769605015792%\n",
      " ACC: 73.25982081323225%\n",
      " F1: 73.15159063877707%\n",
      " RECALL: 73.25982081323225%\n",
      " PRECISION: 73.27927564806548%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.6007567466155%\n",
      " ACC: 72.86009648518264%\n",
      " F1: 72.74030271762804%\n",
      " RECALL: 72.86009648518264%\n",
      " PRECISION: 72.79945109719738%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.58191451379737%\n",
      " ACC: 73.31495520330806%\n",
      " F1: 73.18666339535922%\n",
      " RECALL: 73.31495520330806%\n",
      " PRECISION: 73.26517397546834%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.68552747161355%\n",
      " ACC: 72.97036526533425%\n",
      " F1: 72.7569152224769%\n",
      " RECALL: 72.97036526533425%\n",
      " PRECISION: 72.89198737556237%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.74798732028573%\n",
      " ACC: 72.47415575465196%\n",
      " F1: 72.34726704041199%\n",
      " RECALL: 72.47415575465196%\n",
      " PRECISION: 72.61663661989314%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.25709063523803%\n",
      " ACC: 73.71467953135769%\n",
      " F1: 73.57995573416127%\n",
      " RECALL: 73.71467953135769%\n",
      " PRECISION: 73.67507021745496%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.32308852250706%\n",
      " ACC: 74.1144038594073%\n",
      " F1: 73.90092319583155%\n",
      " RECALL: 74.1144038594073%\n",
      " PRECISION: 74.03337143275853%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.60902758095003%\n",
      " ACC: 73.43900758097863%\n",
      " F1: 73.27435120185571%\n",
      " RECALL: 73.43900758097863%\n",
      " PRECISION: 73.50269431114563%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.95417309533393%\n",
      " ACC: 73.63197794624396%\n",
      " F1: 73.48884021831378%\n",
      " RECALL: 73.63197794624396%\n",
      " PRECISION: 73.59594574473874%\n",
      "第 8 折\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold 8 | \n",
      " AUC_ROC: 90.79272282905609%\n",
      " ACC: 73.17711922811854%\n",
      " F1: 73.09198757852954%\n",
      " RECALL: 73.17711922811854%\n",
      " PRECISION: 73.29029979107459%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.9883390786636%\n",
      " ACC: 73.92143349414198%\n",
      " F1: 73.82391754224363%\n",
      " RECALL: 73.92143349414198%\n",
      " PRECISION: 73.98056414971282%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.60932171765657%\n",
      " ACC: 72.84631288766367%\n",
      " F1: 72.74515635303713%\n",
      " RECALL: 72.84631288766367%\n",
      " PRECISION: 72.9194932816738%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.57451807504381%\n",
      " ACC: 73.32873880082703%\n",
      " F1: 73.23370028355993%\n",
      " RECALL: 73.32873880082703%\n",
      " PRECISION: 73.29715885187831%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.63621984704449%\n",
      " ACC: 73.23225361819435%\n",
      " F1: 73.05014331616758%\n",
      " RECALL: 73.23225361819435%\n",
      " PRECISION: 73.22745398315121%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.9284822874917%\n",
      " ACC: 73.12198483804274%\n",
      " F1: 72.97827444516778%\n",
      " RECALL: 73.12198483804274%\n",
      " PRECISION: 73.20288965564728%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.0768035398007%\n",
      " ACC: 74.15575465196417%\n",
      " F1: 74.03513444463083%\n",
      " RECALL: 74.15575465196417%\n",
      " PRECISION: 74.19502722604027%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.19976411615099%\n",
      " ACC: 74.00413507925569%\n",
      " F1: 73.80678069518093%\n",
      " RECALL: 74.00413507925569%\n",
      " PRECISION: 73.90920840947604%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.61063225329453%\n",
      " ACC: 72.94279807029635%\n",
      " F1: 72.76669023941025%\n",
      " RECALL: 72.94279807029635%\n",
      " PRECISION: 72.96838242638758%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.82764306984676%\n",
      " ACC: 73.60441075120606%\n",
      " F1: 73.49804878368863%\n",
      " RECALL: 73.60441075120606%\n",
      " PRECISION: 73.60581728000261%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.74181003985734%\n",
      " ACC: 72.9841488628532%\n",
      " F1: 72.87076731971403%\n",
      " RECALL: 72.9841488628532%\n",
      " PRECISION: 73.06164983260952%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.60988074751512%\n",
      " ACC: 73.17711922811854%\n",
      " F1: 73.11532736693484%\n",
      " RECALL: 73.17711922811854%\n",
      " PRECISION: 73.32242454673067%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.44348142432958%\n",
      " ACC: 72.18470020675396%\n",
      " F1: 72.07410166062094%\n",
      " RECALL: 72.18470020675396%\n",
      " PRECISION: 72.23130854200774%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.51630955859885%\n",
      " ACC: 73.30117160578911%\n",
      " F1: 73.19411814701317%\n",
      " RECALL: 73.30117160578911%\n",
      " PRECISION: 73.27380027173345%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.55025208007734%\n",
      " ACC: 73.16333563059959%\n",
      " F1: 73.00425712203922%\n",
      " RECALL: 73.16333563059959%\n",
      " PRECISION: 73.1305802303727%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.68014745866921%\n",
      " ACC: 72.59820813232254%\n",
      " F1: 72.44003245660898%\n",
      " RECALL: 72.59820813232254%\n",
      " PRECISION: 72.63333427162334%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.05047156345198%\n",
      " ACC: 73.8525155065472%\n",
      " F1: 73.72230836545278%\n",
      " RECALL: 73.8525155065472%\n",
      " PRECISION: 73.88783000008276%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.2558458197447%\n",
      " ACC: 73.89386629910406%\n",
      " F1: 73.66989386874909%\n",
      " RECALL: 73.89386629910406%\n",
      " PRECISION: 73.81910008057598%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.54232640539291%\n",
      " ACC: 73.31495520330806%\n",
      " F1: 73.15937711178253%\n",
      " RECALL: 73.31495520330806%\n",
      " PRECISION: 73.31594898655057%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.85476613840306%\n",
      " ACC: 73.71467953135769%\n",
      " F1: 73.56666514794293%\n",
      " RECALL: 73.71467953135769%\n",
      " PRECISION: 73.72439521566825%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.89653785412659%\n",
      " ACC: 74.25223983459684%\n",
      " F1: 74.13448955555828%\n",
      " RECALL: 74.25223983459684%\n",
      " PRECISION: 74.43259638204873%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.96977494290948%\n",
      " ACC: 73.81116471399035%\n",
      " F1: 73.73664721164364%\n",
      " RECALL: 73.81116471399035%\n",
      " PRECISION: 73.86823535307066%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.65525428471224%\n",
      " ACC: 73.28738800827016%\n",
      " F1: 73.19756452716342%\n",
      " RECALL: 73.28738800827016%\n",
      " PRECISION: 73.3461611889645%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.65412694265613%\n",
      " ACC: 73.37008959338387%\n",
      " F1: 73.26065727149083%\n",
      " RECALL: 73.37008959338387%\n",
      " PRECISION: 73.34438215988696%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.75272153286585%\n",
      " ACC: 73.30117160578911%\n",
      " F1: 73.13267141596582%\n",
      " RECALL: 73.30117160578911%\n",
      " PRECISION: 73.30215194977231%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.8312262346398%\n",
      " ACC: 73.13576843556167%\n",
      " F1: 72.9815867622159%\n",
      " RECALL: 73.13576843556167%\n",
      " PRECISION: 73.17679998773752%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.12753052917884%\n",
      " ACC: 73.94900068917988%\n",
      " F1: 73.81486400635688%\n",
      " RECALL: 73.94900068917988%\n",
      " PRECISION: 73.91203001386553%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.32997113573751%\n",
      " ACC: 73.97656788421779%\n",
      " F1: 73.7740049277599%\n",
      " RECALL: 73.97656788421779%\n",
      " PRECISION: 73.8934758426759%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.53337169215996%\n",
      " ACC: 73.1909028256375%\n",
      " F1: 72.99232054230274%\n",
      " RECALL: 73.1909028256375%\n",
      " PRECISION: 73.22016784758401%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.94535928515259%\n",
      " ACC: 73.49414197105445%\n",
      " F1: 73.34921004391668%\n",
      " RECALL: 73.49414197105445%\n",
      " PRECISION: 73.49333038232488%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.7303835170713%\n",
      " ACC: 73.75603032391454%\n",
      " F1: 73.64824125373964%\n",
      " RECALL: 73.75603032391454%\n",
      " PRECISION: 73.8557836130816%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.83901843822123%\n",
      " ACC: 73.45279117849759%\n",
      " F1: 73.3898694231573%\n",
      " RECALL: 73.45279117849759%\n",
      " PRECISION: 73.5522358079897%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.683137111842%\n",
      " ACC: 72.94279807029635%\n",
      " F1: 72.82580505818555%\n",
      " RECALL: 72.94279807029635%\n",
      " PRECISION: 72.98560516038538%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.80520934017173%\n",
      " ACC: 73.61819434872501%\n",
      " F1: 73.50859107464028%\n",
      " RECALL: 73.61819434872501%\n",
      " PRECISION: 73.56644339214485%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.66367799938891%\n",
      " ACC: 73.5354927636113%\n",
      " F1: 73.40728778975127%\n",
      " RECALL: 73.5354927636113%\n",
      " PRECISION: 73.58644525178761%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.63147737410078%\n",
      " ACC: 72.90144727773949%\n",
      " F1: 72.74593723585662%\n",
      " RECALL: 72.90144727773949%\n",
      " PRECISION: 72.87458618728924%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.21472837940489%\n",
      " ACC: 73.99035148173674%\n",
      " F1: 73.88414195114241%\n",
      " RECALL: 73.99035148173674%\n",
      " PRECISION: 73.96092419716135%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.25429274991376%\n",
      " ACC: 74.21088904203998%\n",
      " F1: 74.01674840165036%\n",
      " RECALL: 74.21088904203998%\n",
      " PRECISION: 74.18779743983627%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.5163439378252%\n",
      " ACC: 73.12198483804274%\n",
      " F1: 72.96999786260395%\n",
      " RECALL: 73.12198483804274%\n",
      " PRECISION: 73.15758310189105%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.96716196144212%\n",
      " ACC: 73.41144038594074%\n",
      " F1: 73.3053505656795%\n",
      " RECALL: 73.41144038594074%\n",
      " PRECISION: 73.4378843213135%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 91.00774457457509%\n",
      " ACC: 74.22467263955892%\n",
      " F1: 74.1298918119952%\n",
      " RECALL: 74.22467263955892%\n",
      " PRECISION: 74.40111176163208%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.87058021048216%\n",
      " ACC: 74.07305306685045%\n",
      " F1: 73.98246197473247%\n",
      " RECALL: 74.07305306685045%\n",
      " PRECISION: 74.17592486208656%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.71943650905438%\n",
      " ACC: 73.37008959338387%\n",
      " F1: 73.27244730445771%\n",
      " RECALL: 73.37008959338387%\n",
      " PRECISION: 73.47900235503617%\n",
      "[0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400]\n",
      "average roc score: [0.8601453118149568, 0.9036372590303688, 0.9028844543145015, 0.9059153770725032, 0.9060927651566617, 0.9077229124729762, 0.9073841282963929, 0.9076252938109131, 0.9076244764742624, 0.9072730739441435, 0.9085491927651018, 0.9076492354003749, 0.9079716861060863, 0.9084268464195251, 0.908650653036359]\n",
      "average acc_score: [0.6567470709855272, 0.727250172294969, 0.7262991040661613, 0.7314403859407304, 0.7305444521019986, 0.7329014472777395, 0.7345830461750518, 0.7331495520330806, 0.7329565816678153, 0.733039283252929, 0.7336044107512061, 0.732736044107512, 0.7351895244658856, 0.7345692625775329, 0.7364576154376292]\n",
      "average f1_score: [0.6501488484228044, 0.7257252377056265, 0.7250328796341726, 0.7300061605827395, 0.729133062262375, 0.7313210255316146, 0.7331956358334728, 0.7318455377113424, 0.731546423953336, 0.7316499289295509, 0.7321959774822207, 0.7314289685550757, 0.7338253535139541, 0.7331692307050912, 0.7352228559725098]\n",
      "average recall_score: [0.6567470709855272, 0.727250172294969, 0.7262991040661613, 0.7314403859407304, 0.7305444521019986, 0.7329014472777395, 0.7345830461750518, 0.7331495520330806, 0.7329565816678153, 0.733039283252929, 0.7336044107512061, 0.732736044107512, 0.7351895244658856, 0.7345692625775329, 0.7364576154376292]\n",
      "average precision_score: [0.6506413968205838, 0.7275136009908985, 0.7260205714481961, 0.7315394731728115, 0.7306028502121369, 0.7332631492455459, 0.7349614230013063, 0.7332392783637702, 0.7332273591361792, 0.733106174993847, 0.733771236899483, 0.7330213207539312, 0.7354319819806909, 0.7347359627653037, 0.7368277028701786]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "roc_ = []\n",
    "acc_ = []\n",
    "f1_ = []\n",
    "recall_ = []\n",
    "precision_ = []\n",
    "ii = []\n",
    "\n",
    "for i in tqdm_notebook(range(0, 1500, 100)):\n",
    "    name = \"data_w2v_\" + str(i) + \".csv\"\n",
    "    data = pd.read_csv(name)\n",
    "\n",
    "    category_col = ['attacktype1_txt', 'targsubtype1_txt', 'weapsubtype1_txt']\n",
    "    data[category_col] = data[category_col].astype('category')\n",
    "    X = data.drop(columns=['risk'], axis=1)\n",
    "    y = data['risk']\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    splits = kf.split(X, y)\n",
    "    \n",
    "    #lightGbm \n",
    "    lgb_roc_scores = []\n",
    "    lgb_acc_scores = []\n",
    "    lgb_f1_scores = []\n",
    "    lgb_recall_scores = []\n",
    "    lgb_precision_scores = []\n",
    "    lgb_feature_importances = pd.DataFrame(index=None)\n",
    "    lgb_feature_importances['features'] = data.drop(['risk'], axis=1).columns\n",
    "\n",
    "    for k, (train_indices, test_indices) in enumerate(splits):\n",
    "        print(\"第 %d 折\\n\" % (k + 1))\n",
    "        X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "        y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "        labels = [0, 1, 2, 3]\n",
    "        y_one_hot = label_binarize(y_test, classes=labels)\n",
    "\n",
    "        LGB = lgb.LGBMClassifier(random_state=0, \n",
    "                                 learning_rate=lr__[count], \n",
    "                                 min_child_samples=mcs__[count],\n",
    "                                 max_depth=md__[count], \n",
    "                                 num_leaves=nl__[count], \n",
    "                                 colsample_bytree=cb__[count],\n",
    "                                 reg_alpha=ra__[count],\n",
    "                                 reg_lambda=rl__[count],\n",
    "                                )\n",
    "        LGB.fit(X_train, y_train, categorical_feature=category_col)\n",
    "        lgb_feature_importances[f'fold_{k+1}'] = LGB.feature_importances_\n",
    "        y_pred_prob = LGB.predict_proba(X_test)\n",
    "        y_pred = LGB.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_one_hot, y_pred_prob, multi_class=\"ovo\", average='weighted')\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    #     G_mean = math.sqrt(recall * specificity)\n",
    "        print(f\" Fold {k + 1} | \" )\n",
    "        print(f\" AUC_ROC: { roc_auc * 100}%\" )\n",
    "        print(f\" ACC: { acc * 100}%\" )\n",
    "        print(f\" F1: { f1 * 100}%\" )\n",
    "        print(f\" RECALL: { recall * 100}%\" )\n",
    "        print(f\" PRECISION: { precision * 100}%\" )\n",
    "        lgb_f1_scores.append(f1)\n",
    "        lgb_roc_scores.append(roc_auc)\n",
    "        lgb_acc_scores.append(acc)\n",
    "        lgb_recall_scores.append(recall)\n",
    "        lgb_precision_scores.append(precision)\n",
    "    count = count + 1\n",
    "    \n",
    "    ii.append(i)\n",
    "    roc_.append(np.mean(lgb_roc_scores))\n",
    "    acc_.append(np.mean(lgb_acc_scores))\n",
    "    f1_.append(np.mean(lgb_f1_scores))\n",
    "    recall_.append(np.mean(lgb_recall_scores))\n",
    "    precision_.append(np.mean(lgb_precision_scores))\n",
    "#     print(f'average roc score: {np.mean(lgb_roc_scores)}')\n",
    "#     print(f'average acc_score: {np.mean(lgb_acc_scores)}')\n",
    "#     print(f'average f1_score: {np.mean(lgb_f1_scores)}')\n",
    "#     print(f'average recall_score: {np.mean(lgb_recall_scores)}')\n",
    "#     print(f'average precision_score: {np.mean(lgb_precision_scores)}')\n",
    "print(ii)\n",
    "print(f'average roc score: {roc_}')\n",
    "print(f'average acc_score: {acc_}')\n",
    "print(f'average f1_score: {f1_}')\n",
    "print(f'average recall_score: {recall_}')\n",
    "print(f'average precision_score: {precision_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f18023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_ = [0.8601453118149568, 0.9036372590303688, 0.9028844543145015, 0.9059153770725032, 0.9060927651566617, 0.9077229124729762, 0.9073841282963929, 0.9076252938109131, 0.9076244764742624, 0.9072730739441435, 0.9085491927651018, 0.9076492354003749, 0.9079716861060863, 0.9084268464195251, 0.908650653036359]\n",
    "acc_ = [0.6567470709855272, 0.727250172294969, 0.7262991040661613, 0.7314403859407304, 0.7305444521019986, 0.7329014472777395, 0.7345830461750518, 0.7331495520330806, 0.7329565816678153, 0.733039283252929, 0.7336044107512061, 0.732736044107512, 0.7351895244658856, 0.7345692625775329, 0.7364576154376292]\n",
    "f1_ = [0.6501488484228044, 0.7257252377056265, 0.7250328796341726, 0.7300061605827395, 0.729133062262375, 0.7313210255316146, 0.7331956358334728, 0.7318455377113424, 0.731546423953336, 0.7316499289295509, 0.7321959774822207, 0.7314289685550757, 0.7338253535139541, 0.7331692307050912, 0.7352228559725098]\n",
    "recall_ = [0.6567470709855272, 0.727250172294969, 0.7262991040661613, 0.7314403859407304, 0.7305444521019986, 0.7329014472777395, 0.7345830461750518, 0.7331495520330806, 0.7329565816678153, 0.733039283252929, 0.7336044107512061, 0.732736044107512, 0.7351895244658856, 0.7345692625775329, 0.7364576154376292]\n",
    "precision_ = [0.6506413968205838, 0.7275136009908985, 0.7260205714481961, 0.7315394731728115, 0.7306028502121369, 0.7332631492455459, 0.7349614230013063, 0.7332392783637702, 0.7332273591361792, 0.733106174993847, 0.733771236899483, 0.7330213207539312, 0.7354319819806909, 0.7347359627653037, 0.7368277028701786]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182d09a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "#导入库\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "#设定画布。dpi越大图越清晰，绘图时间越久\n",
    "fig=plt.figure(figsize=(10, 4), dpi=200)\n",
    "#导入数据\n",
    "x = range(0, 1500, 100)\n",
    "x_ = range(0, 1500, 200)\n",
    "y_1 = [0.86, 0.87, 0.88, 0.89, 0.90]\n",
    "y_2 = [0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73]\n",
    "y1 = roc_\n",
    "y2 = acc_\n",
    "y3 = f1_\n",
    "y4 = recall_\n",
    "y5 = precision_\n",
    "#绘图命令\n",
    "plt.subplot(1,2,1) # 子图的行、列、索引\n",
    "plt.plot(x, y1, lw=1, ls='-', c='b', alpha=0.5, label='AUC')\n",
    "\n",
    "plt.legend()  \n",
    "plt.xticks(x_)\n",
    "plt.yticks(y_1)\n",
    "plt.title(\"Word2vec\")\n",
    "plt.xlabel(\"Feature dimension\") \n",
    "plt.ylabel(\"Performance\")\n",
    "\n",
    "plt.subplot(1,2,2) # 子图的行、列、索引\n",
    "plt.plot(x, y2, lw=1, ls='-', c='r', alpha=0.5, label='Accuracy')\n",
    "plt.plot(x, y3, lw=1, ls='-', c='g', alpha=0.5, label='F1-score')\n",
    "plt.plot(x, y4, lw=1, ls='-', c='k', alpha=0.5, label='Sensitivity')\n",
    "plt.plot(x, y5, lw=1, ls='-', c='m', alpha=0.5, label='Precision')\n",
    "\n",
    "plt.legend()  \n",
    "plt.xticks(x_)\n",
    "plt.yticks(y_2)\n",
    "plt.title(\"Word2vec\")\n",
    "plt.xlabel(\"Feature dimension\") \n",
    "plt.ylabel(\"Performance\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e1f561d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908650653036359\n",
      "0.7364576154376292\n",
      "0.7352228559725098\n",
      "0.7364576154376292\n",
      "0.7368277028701786\n"
     ]
    }
   ],
   "source": [
    "print(max(roc_))\n",
    "print(max(acc_))\n",
    "print(max(f1_))\n",
    "print(max(recall_))\n",
    "print(max(precision_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e24a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
