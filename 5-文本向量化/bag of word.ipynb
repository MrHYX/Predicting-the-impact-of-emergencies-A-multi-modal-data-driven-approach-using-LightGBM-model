{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66cdeeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.book import *\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm import tqdm_notebook\n",
    "import joblib\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fc38e64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city   latitude   longitude                 attacktype1_txt  \\\n",
      "0        Cairo  37.005105  -89.176269                   Armed Assault   \n",
      "1      Oakland  37.791927 -122.225906               Bombing/Explosion   \n",
      "2      Madison  43.076592  -89.412488  Facility/Infrastructure Attack   \n",
      "3      Madison  43.072950  -89.386694  Facility/Infrastructure Attack   \n",
      "4       Denver  39.758968 -104.876305  Facility/Infrastructure Attack   \n",
      "...        ...        ...         ...                             ...   \n",
      "72545     Aden  12.849085   45.037275               Bombing/Explosion   \n",
      "72546    Bheri  28.709444   82.163611  Facility/Infrastructure Attack   \n",
      "72547    Sabaa  15.305307   43.019490               Bombing/Explosion   \n",
      "72548    Kabul  34.523842   69.140304                   Armed Assault   \n",
      "72549  Wichita  37.688889  -97.336111                   Assassination   \n",
      "\n",
      "                                        targsubtype1_txt  \\\n",
      "0        Police Building (headquarters, station, school)   \n",
      "1                                            Electricity   \n",
      "2                    Military Recruiting Station/Academy   \n",
      "3                    Government Building/Facility/Office   \n",
      "4                    Military Recruiting Station/Academy   \n",
      "...                                                  ...   \n",
      "72545                                  International NGO   \n",
      "72546  Government Personnel (excluding police, military)   \n",
      "72547                          House/Apartment/Residence   \n",
      "72548                                          Protester   \n",
      "72549                                          Personnel   \n",
      "\n",
      "                                weapsubtype1_txt  date  risk  \\\n",
      "0                               Unknown Gun Type     4     1   \n",
      "1                         Unknown Explosive Type     5     1   \n",
      "2                   Molotov Cocktail/Petrol Bomb     5     1   \n",
      "3                            Gasoline or Alcohol     6     1   \n",
      "4                   Molotov Cocktail/Petrol Bomb     2     1   \n",
      "...                                          ...   ...   ...   \n",
      "72545                     Unknown Explosive Type     4     1   \n",
      "72546                        Gasoline or Alcohol     4     1   \n",
      "72547  Projectile (rockets, mortars, RPGs, etc.)     4     1   \n",
      "72548                           Unknown Gun Type     4     2   \n",
      "72549                                    Handgun     4     2   \n",
      "\n",
      "                                                 summary  \n",
      "0       Unknown African American assailants fired sev...  \n",
      "1       Unknown perpetrators detonated explosives at ...  \n",
      "2       Karl Armstrong, a member of the New Years Gan...  \n",
      "3       Karl Armstrong, a member of the New Years Gan...  \n",
      "4       Unknown perpetrators threw a Molotov cocktail...  \n",
      "...                                                  ...  \n",
      "72545   An explosive device detonated targeting the o...  \n",
      "72546   Assailants set fire to the vehicle of Ganesh ...  \n",
      "72547   Assailants fired mortar shells targeting resi...  \n",
      "72548   No group claimed responsibility for the incident  \n",
      "72549   An assailant opened fire on Dr. George Tiller...  \n",
      "\n",
      "[72550 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../2-数据转换/data_nor.csv\")\n",
    "data_columns = pd.read_csv(\"../../3-特征选取/data_columns.csv\")\n",
    "columns = data_columns.columns.values\n",
    "columns = np.append(columns, [\"risk\", \"summary\"])\n",
    "data = data[columns]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b4b6e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           city  latitude  longitude                 attacktype1_txt  \\\n",
      "0      0.181904  0.681564   0.204755                   Armed Assault   \n",
      "1      0.688351  0.688223   0.106546               Bombing/Explosion   \n",
      "2      0.558561  0.732945   0.204053  Facility/Infrastructure Attack   \n",
      "3      0.558561  0.732914   0.204130  Facility/Infrastructure Attack   \n",
      "4      0.249211  0.704869   0.158102  Facility/Infrastructure Attack   \n",
      "...         ...       ...        ...                             ...   \n",
      "72545  0.009873  0.477141   0.603580               Bombing/Explosion   \n",
      "72546  0.142187  0.611361   0.713903  Facility/Infrastructure Attack   \n",
      "72547  0.787440  0.497927   0.597584               Bombing/Explosion   \n",
      "72548  0.420521  0.660566   0.675203                   Armed Assault   \n",
      "72549  0.974123  0.687351   0.180508                   Assassination   \n",
      "\n",
      "                                        targsubtype1_txt  \\\n",
      "0        Police Building (headquarters, station, school)   \n",
      "1                                            Electricity   \n",
      "2                    Military Recruiting Station/Academy   \n",
      "3                    Government Building/Facility/Office   \n",
      "4                    Military Recruiting Station/Academy   \n",
      "...                                                  ...   \n",
      "72545                                  International NGO   \n",
      "72546  Government Personnel (excluding police, military)   \n",
      "72547                          House/Apartment/Residence   \n",
      "72548                                          Protester   \n",
      "72549                                          Personnel   \n",
      "\n",
      "                                weapsubtype1_txt      date  risk  \\\n",
      "0                               Unknown Gun Type  0.500000     1   \n",
      "1                         Unknown Explosive Type  0.666667     1   \n",
      "2                   Molotov Cocktail/Petrol Bomb  0.666667     1   \n",
      "3                            Gasoline or Alcohol  0.833333     1   \n",
      "4                   Molotov Cocktail/Petrol Bomb  0.166667     1   \n",
      "...                                          ...       ...   ...   \n",
      "72545                     Unknown Explosive Type  0.500000     1   \n",
      "72546                        Gasoline or Alcohol  0.500000     1   \n",
      "72547  Projectile (rockets, mortars, RPGs, etc.)  0.500000     1   \n",
      "72548                           Unknown Gun Type  0.500000     2   \n",
      "72549                                    Handgun  0.500000     2   \n",
      "\n",
      "                                                 summary  \n",
      "0       Unknown African American assailants fired sev...  \n",
      "1       Unknown perpetrators detonated explosives at ...  \n",
      "2       Karl Armstrong, a member of the New Years Gan...  \n",
      "3       Karl Armstrong, a member of the New Years Gan...  \n",
      "4       Unknown perpetrators threw a Molotov cocktail...  \n",
      "...                                                  ...  \n",
      "72545   An explosive device detonated targeting the o...  \n",
      "72546   Assailants set fire to the vehicle of Ganesh ...  \n",
      "72547   Assailants fired mortar shells targeting resi...  \n",
      "72548   No group claimed responsibility for the incident  \n",
      "72549   An assailant opened fire on Dr. George Tiller...  \n",
      "\n",
      "[72550 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(list(data[\"city\"].values))\n",
    "data[\"city\"] = encoder.transform(list(data[\"city\"].values))\n",
    "\n",
    "number_columns = [ col for col in data.columns if data[col].dtype != 'object' ]\n",
    "number_columns.remove(\"risk\")\n",
    "#min-max\n",
    "for col in number_columns:\n",
    "    data[col] = (data[col] - data[col].min()) / (data[col].max() - data[col].min())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e653300",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_txt.csv', index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a39639cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag\n",
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d61d69c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021965980529785156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 72550,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a702c927cc2349269111d2a898bf2ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           city  latitude  longitude                 attacktype1_txt  \\\n",
      "0      0.181904  0.681564   0.204755                   Armed Assault   \n",
      "1      0.688351  0.688223   0.106546               Bombing/Explosion   \n",
      "2      0.558561  0.732945   0.204053  Facility/Infrastructure Attack   \n",
      "3      0.558561  0.732914   0.204130  Facility/Infrastructure Attack   \n",
      "4      0.249211  0.704869   0.158102  Facility/Infrastructure Attack   \n",
      "...         ...       ...        ...                             ...   \n",
      "72545  0.009873  0.477141   0.603580               Bombing/Explosion   \n",
      "72546  0.142187  0.611361   0.713903  Facility/Infrastructure Attack   \n",
      "72547  0.787440  0.497927   0.597584               Bombing/Explosion   \n",
      "72548  0.420521  0.660566   0.675203                   Armed Assault   \n",
      "72549  0.974123  0.687351   0.180508                   Assassination   \n",
      "\n",
      "                                        targsubtype1_txt  \\\n",
      "0        Police Building (headquarters, station, school)   \n",
      "1                                            Electricity   \n",
      "2                    Military Recruiting Station/Academy   \n",
      "3                    Government Building/Facility/Office   \n",
      "4                    Military Recruiting Station/Academy   \n",
      "...                                                  ...   \n",
      "72545                                  International NGO   \n",
      "72546  Government Personnel (excluding police, military)   \n",
      "72547                          House/Apartment/Residence   \n",
      "72548                                          Protester   \n",
      "72549                                          Personnel   \n",
      "\n",
      "                                weapsubtype1_txt      date  risk  \\\n",
      "0                               Unknown Gun Type  0.500000     1   \n",
      "1                         Unknown Explosive Type  0.666667     1   \n",
      "2                   Molotov Cocktail/Petrol Bomb  0.666667     1   \n",
      "3                            Gasoline or Alcohol  0.833333     1   \n",
      "4                   Molotov Cocktail/Petrol Bomb  0.166667     1   \n",
      "...                                          ...       ...   ...   \n",
      "72545                     Unknown Explosive Type  0.500000     1   \n",
      "72546                        Gasoline or Alcohol  0.500000     1   \n",
      "72547  Projectile (rockets, mortars, RPGs, etc.)  0.500000     1   \n",
      "72548                           Unknown Gun Type  0.500000     2   \n",
      "72549                                    Handgun  0.500000     2   \n",
      "\n",
      "                                                 summary  \n",
      "0       unknown african american assailants fired sev...  \n",
      "1       unknown perpetrators detonated explosives at ...  \n",
      "2       karl armstrong, a member of the new years gan...  \n",
      "3       karl armstrong, a member of the new years gan...  \n",
      "4       unknown perpetrators threw a molotov cocktail...  \n",
      "...                                                  ...  \n",
      "72545   an explosive device detonated targeting the o...  \n",
      "72546   assailants set fire to the vehicle of ganesh ...  \n",
      "72547   assailants fired mortar shells targeting resi...  \n",
      "72548   no group claimed responsibility for the incident  \n",
      "72549   an assailant opened fire on dr. george tiller...  \n",
      "\n",
      "[72550 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm_notebook(range(data.summary.shape[0])):\n",
    "    data.summary[row] = data.summary[row].lower()\n",
    "# print(data.summary)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5476b2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set reviews...\n",
      "\n",
      "Review 1000 of 72550\n",
      "Review 2000 of 72550\n",
      "Review 3000 of 72550\n",
      "Review 4000 of 72550\n",
      "Review 5000 of 72550\n",
      "Review 6000 of 72550\n",
      "Review 7000 of 72550\n",
      "Review 8000 of 72550\n",
      "Review 9000 of 72550\n",
      "Review 10000 of 72550\n",
      "Review 11000 of 72550\n",
      "Review 12000 of 72550\n",
      "Review 13000 of 72550\n",
      "Review 14000 of 72550\n",
      "Review 15000 of 72550\n",
      "Review 16000 of 72550\n",
      "Review 17000 of 72550\n",
      "Review 18000 of 72550\n",
      "Review 19000 of 72550\n",
      "Review 20000 of 72550\n",
      "Review 21000 of 72550\n",
      "Review 22000 of 72550\n",
      "Review 23000 of 72550\n",
      "Review 24000 of 72550\n",
      "Review 25000 of 72550\n",
      "Review 26000 of 72550\n",
      "Review 27000 of 72550\n",
      "Review 28000 of 72550\n",
      "Review 29000 of 72550\n",
      "Review 30000 of 72550\n",
      "Review 31000 of 72550\n",
      "Review 32000 of 72550\n",
      "Review 33000 of 72550\n",
      "Review 34000 of 72550\n",
      "Review 35000 of 72550\n",
      "Review 36000 of 72550\n",
      "Review 37000 of 72550\n",
      "Review 38000 of 72550\n",
      "Review 39000 of 72550\n",
      "Review 40000 of 72550\n",
      "Review 41000 of 72550\n",
      "Review 42000 of 72550\n",
      "Review 43000 of 72550\n",
      "Review 44000 of 72550\n",
      "Review 45000 of 72550\n",
      "Review 46000 of 72550\n",
      "Review 47000 of 72550\n",
      "Review 48000 of 72550\n",
      "Review 49000 of 72550\n",
      "Review 50000 of 72550\n",
      "Review 51000 of 72550\n",
      "Review 52000 of 72550\n",
      "Review 53000 of 72550\n",
      "Review 54000 of 72550\n",
      "Review 55000 of 72550\n",
      "Review 56000 of 72550\n",
      "Review 57000 of 72550\n",
      "Review 58000 of 72550\n",
      "Review 59000 of 72550\n",
      "Review 60000 of 72550\n",
      "Review 61000 of 72550\n",
      "Review 62000 of 72550\n",
      "Review 63000 of 72550\n",
      "Review 64000 of 72550\n",
      "Review 65000 of 72550\n",
      "Review 66000 of 72550\n",
      "Review 67000 of 72550\n",
      "Review 68000 of 72550\n",
      "Review 69000 of 72550\n",
      "Review 70000 of 72550\n",
      "Review 71000 of 72550\n",
      "Review 72000 of 72550\n"
     ]
    }
   ],
   "source": [
    "num_reviews = data[\"summary\"].size\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "print(\"Cleaning and parsing the training set reviews...\\n\")\n",
    "clean_train_reviews = []\n",
    "for i in range(num_reviews):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print(\"Review %d of %d\" % ( i+1, num_reviews ))                                                                    \n",
    "    clean_train_reviews.append( review_to_words( data[\"summary\"][i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ff47941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018948793411254883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 14,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b41853b36154fdca91a07d46198a8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_bow_nt_100.csv\n",
      "data_bow_nt_200.csv\n",
      "data_bow_nt_300.csv\n",
      "data_bow_nt_400.csv\n",
      "data_bow_nt_500.csv\n",
      "data_bow_nt_600.csv\n",
      "data_bow_nt_700.csv\n",
      "data_bow_nt_800.csv\n",
      "data_bow_nt_900.csv\n",
      "data_bow_nt_1000.csv\n",
      "data_bow_nt_1100.csv\n",
      "data_bow_nt_1200.csv\n",
      "data_bow_nt_1300.csv\n",
      "data_bow_nt_1400.csv\n"
     ]
    }
   ],
   "source": [
    "print( \"Creating the bag of words...\\n\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "# features = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "for i in tqdm_notebook(range(100, 1500, 100)):\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = i) \n",
    "    train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "    # Numpy arrays are easy to work with, so convert the result to an \n",
    "    # array\n",
    "    train_data_featuress = train_data_features.toarray()\n",
    "    # print(train_data_featuress)\n",
    "    column_summary = []\n",
    "    for j in range(train_data_featuress.shape[1]):\n",
    "        col = \"summary_\" + str(j)\n",
    "        column_summary.append(col)\n",
    "    data_summary = pd.DataFrame(train_data_featuress, columns=column_summary)\n",
    "    data_concat = pd.concat([data, data_summary], axis=1, ignore_index=False)\n",
    "    data_concat.drop(columns=['summary'], axis=1, inplace=True)\n",
    "    name = \"data_bow_nt_\" + str(i) + '.csv'\n",
    "    data_concat.to_csv(name, index=False, encoding='utf_8_sig')\n",
    "#     features = features + 10\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1ef15a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_func(solution, solution_idx):\n",
    "    # 从解决方案中提取超参数\n",
    "    learning_rate = solution[0]\n",
    "    min_child_samples = int(solution[1])\n",
    "    max_depth = int(solution[2])\n",
    "    num_leaves = int(solution[3])\n",
    "    colsample_bytree = (solution[4])\n",
    "    reg_alpha = solution[5]\n",
    "    reg_lambda = solution[6]\n",
    "    \n",
    "    print(learning_rate, min_child_samples, max_depth, num_leaves,\n",
    "          colsample_bytree, reg_alpha, reg_lambda)\n",
    "    # 定义LightBGM的函数\n",
    "    LGB = lgb.LGBMClassifier(learning_rate=learning_rate, # 学习率\n",
    "                             min_child_samples=min_child_samples,\n",
    "                             max_depth=max_depth, # 树的最大深度\n",
    "                             num_leaves=num_leaves, \n",
    "                             colsample_bytree=colsample_bytree,\n",
    "                             reg_alpha=reg_alpha,\n",
    "                             reg_lambda=reg_lambda,\n",
    "                             random_state=0 # 随机种子\n",
    "                            )\n",
    "\n",
    "    # 利用训练数据训练LightLGB分类器\n",
    "    LGB.fit(X_train, y_train, categorical_feature=category_col)\n",
    "    # 对测试数据进行预测\n",
    "#     y_pred_prob = LGB.predict_proba(X_test)\n",
    "    y_pred = LGB.predict(X_test)\n",
    "    # 计算准确率\n",
    "#     acc = accuracy_score(y_test, y_pred)\n",
    "#     f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "#     precision = precision_score(y_test, y_pred, average='weighted')\n",
    "#     roc_auc = roc_auc_score(y_one_hot, y_pred_prob, multi_class=\"ovo\", average=\"weighted\")\n",
    "#     print('当前准确率：', precision)\n",
    "    # 返回适应函数分数（准确性）\n",
    "    fitness = recall\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02277c22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           city  latitude  longitude                 attacktype1_txt  \\\n",
      "0      0.181904  0.681564   0.204755                   Armed Assault   \n",
      "1      0.688351  0.688223   0.106546               Bombing/Explosion   \n",
      "2      0.558561  0.732945   0.204053  Facility/Infrastructure Attack   \n",
      "3      0.558561  0.732914   0.204130  Facility/Infrastructure Attack   \n",
      "4      0.249211  0.704869   0.158102  Facility/Infrastructure Attack   \n",
      "...         ...       ...        ...                             ...   \n",
      "72545  0.009873  0.477141   0.603580               Bombing/Explosion   \n",
      "72546  0.142187  0.611361   0.713903  Facility/Infrastructure Attack   \n",
      "72547  0.787440  0.497927   0.597584               Bombing/Explosion   \n",
      "72548  0.420521  0.660566   0.675203                   Armed Assault   \n",
      "72549  0.974123  0.687351   0.180508                   Assassination   \n",
      "\n",
      "                                        targsubtype1_txt  \\\n",
      "0        Police Building (headquarters, station, school)   \n",
      "1                                            Electricity   \n",
      "2                    Military Recruiting Station/Academy   \n",
      "3                    Government Building/Facility/Office   \n",
      "4                    Military Recruiting Station/Academy   \n",
      "...                                                  ...   \n",
      "72545                                  International NGO   \n",
      "72546  Government Personnel (excluding police, military)   \n",
      "72547                          House/Apartment/Residence   \n",
      "72548                                          Protester   \n",
      "72549                                          Personnel   \n",
      "\n",
      "                                weapsubtype1_txt      date  risk  \n",
      "0                               Unknown Gun Type  0.500000     1  \n",
      "1                         Unknown Explosive Type  0.666667     1  \n",
      "2                   Molotov Cocktail/Petrol Bomb  0.666667     1  \n",
      "3                            Gasoline or Alcohol  0.833333     1  \n",
      "4                   Molotov Cocktail/Petrol Bomb  0.166667     1  \n",
      "...                                          ...       ...   ...  \n",
      "72545                     Unknown Explosive Type  0.500000     1  \n",
      "72546                        Gasoline or Alcohol  0.500000     1  \n",
      "72547  Projectile (rockets, mortars, RPGs, etc.)  0.500000     1  \n",
      "72548                           Unknown Gun Type  0.500000     2  \n",
      "72549                                    Handgun  0.500000     2  \n",
      "\n",
      "[72550 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_txt.csv\")\n",
    "data.drop(columns=[\"summary\"], axis=1, inplace=True)\n",
    "print(data)\n",
    "data.to_csv('data_bow_nt_0.csv', index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48d1178a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014959096908569336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 15,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2594ccf8af4b458381944e63215f2f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6610613370089593\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6516884906960717\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6485182632667126\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6573397656788422\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.6609235010337698\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.6566505858028946\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6606478290833908\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.6526533425223984\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6657477601654032\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.6514128187456927\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7177119228118539\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7219848380427292\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7232253618194349\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7241902136457615\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7230875258442453\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7236388697450035\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.726671261199173\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7291523087525844\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7229496898690558\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7196416264645072\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7331495520330806\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7385251550654721\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7334252239834597\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7383873190902825\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.743487250172295\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 43.75872113] with fitness value 0.7359062715368712\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7411440385940731\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7415575465196417\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 56.80445611\n",
      " 43.75872113] with fitness value 0.743762922122674\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7328738800827016\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.57600543 64.58941131\n",
      " 92.55966383] with fitness value 0.7357684355616816\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7390764989662302\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7378359751895245\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7421088904203997\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7447277739490007\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7356305995864921\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7419710544452102\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7399035148173674\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7455547898001378\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7360441075120606\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7363197794624396\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7405926946933149\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7346657477601654\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7396278428669882\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7478980013783597\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7372846312887664\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7423845623707788\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7425223983459683\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7455547898001378\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7345279117849759\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7364576154376292\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7393521709166092\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7364576154376292\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7414197105444521\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7426602343211578\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7363197794624396\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7393521709166092\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7405926946933149\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7441764300482426\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 80.21387862  0.76167462 56.80445611\n",
      " 43.75872113] with fitness value 0.7378359751895245\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7345279117849759\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7422467263955892\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7360441075120606\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7404548587181254\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7448656099241903\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7346657477601654\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7427980702963474\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7401791867677464\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7456926257753274\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7341144038594073\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7368711233631978\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7443142660234321\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7349414197105445\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7407305306685045\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 43.75872113] with fitness value 0.7474844934527912\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7338387319090283\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.743762922122674\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7444521019986217\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.749276361130255\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7371467953135769\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7385251550654721\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7425223983459683\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7396278428669882\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7396278428669882\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7474844934527912\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7401791867677464\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7452791178497588\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7415575465196417\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7440385940730531\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7376981392143349\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7376981392143349\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7423845623707788\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7357684355616816\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7447277739490007\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7458304617505169\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7403170227429359\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7472088215024121\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7427980702963474\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7485871812543073\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7376981392143349\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7356305995864921\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7421088904203997\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7367332873880083\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7422467263955892\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.749276361130255\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7385251550654721\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7459682977257064\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7458304617505169\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.746381805651275\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 10 折\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7345279117849759\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7371467953135769\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.743487250172295\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7371467953135769\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7454169538249483\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.749276361130255\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7396278428669882\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.746106133700896\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7443142660234321\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7502412129565816\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7378359751895245\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.735354927636113\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7425223983459683\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 56.76390238  0.76167462 56.80445611\n",
      " 43.75872113] with fitness value 0.7407305306685045\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7454169538249483\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7467953135768436\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7389386629910406\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7439007580978635\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7415575465196417\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7494141971054445\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7433494141971054\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7393521709166092\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.743762922122674\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7405926946933149\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7422467263955892\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7498277050310131\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 6 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7393521709166092\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7456926257753274\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7474844934527912\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.7476223294279807\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 37 6 56 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7388008270158511\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 1 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 37 6 80 0.7616746199103354 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.89285527 37.18352149  6.36818126 80.21387862  0.76167462 56.80445611\n",
      " 92.55966383] with fitness value 0.7407305306685045\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 37\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 2 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.76167462 64.58941131\n",
      " 43.75872113] with fitness value 0.743762922122674\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.7616746199103354\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 3 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7405926946933149\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 4 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 48.36482422  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7447277739490007\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 48\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 5 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7483115093039283\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 6 折\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7401791867677464\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 7 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 64.58941130666561 92.5596638292661\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7474844934527912\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "第 8 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.892855270774259 37 6 56 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.892855270774259 48 6 56 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 56.80445610939323 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 56.76390238  0.48128932 64.58941131\n",
      " 43.75872113] with fitness value 0.7429359062715368\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 56\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 64.58941130666561\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 9 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 37 9 80 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 37 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.55332537 37.18352149  9.43868727 80.21387862  0.48128932 56.80445611\n",
      " 43.75872113] with fitness value 0.7507925568573398\n",
      "Best learning rate is 0.5533253688880515\n",
      "Best min child samples is 37\n",
      "Best max depth is 9\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.4812893194050143\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 43.75872112626925\n",
      "第 10 折\n",
      "\n",
      "0.5533253688880515 37 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.08032569761590806 8 1 84 0.8003410758548655 87.00121482468191 97.8618342232764\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.4812893194050143 64.58941130666561 43.75872112626925\n",
      "0.892855270774259 48 6 80 0.5760054277776141 56.80445610939323 92.5596638292661\n",
      "0.5533253688880515 48 9 56 0.7616746199103354 64.58941130666561 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "0.5533253688880515 48 9 80 0.4812893194050143 56.80445610939323 43.75872112626925\n",
      "Best solution is [ 0.89285527 48.36482422  6.36818126 80.21387862  0.57600543 56.80445611\n",
      " 92.55966383] with fitness value 0.7385251550654721\n",
      "Best learning rate is 0.892855270774259\n",
      "Best min child samples is 48\n",
      "Best max depth is 6\n",
      "Best num leaves is 80\n",
      "Best colsample bytree is 0.5760054277776141\n",
      "Best reg_alpha is 56.80445610939323\n",
      "Best reg_lambda is 92.5596638292661\n",
      "[0.6657477601654032, 0.7291523087525844, 0.743762922122674, 0.7455547898001378, 0.7478980013783597, 0.7441764300482426, 0.7456926257753274, 0.749276361130255, 0.7474844934527912, 0.7485871812543073, 0.749276361130255, 0.7502412129565816, 0.7494141971054445, 0.7498277050310131, 0.7507925568573398] [0.5533253688880515, 0.892855270774259, 0.5533253688880515, 0.892855270774259, 0.892855270774259, 0.5533253688880515, 0.5533253688880515, 0.892855270774259, 0.5533253688880515, 0.892855270774259, 0.892855270774259, 0.5533253688880515, 0.892855270774259, 0.892855270774259, 0.5533253688880515] [37, 48, 37, 48, 48, 37, 48, 48, 37, 48, 48, 37, 37, 48, 37] [9, 6, 9, 6, 6, 9, 9, 6, 9, 6, 6, 9, 6, 6, 9] [80, 80, 80, 80, 80, 80, 56, 80, 80, 80, 80, 56, 80, 80, 80] [0.7616746199103354, 0.5760054277776141, 0.7616746199103354, 0.5760054277776141, 0.5760054277776141, 0.7616746199103354, 0.7616746199103354, 0.5760054277776141, 0.7616746199103354, 0.5760054277776141, 0.5760054277776141, 0.4812893194050143, 0.7616746199103354, 0.5760054277776141, 0.4812893194050143] [64.58941130666561, 56.80445610939323, 56.80445610939323, 56.80445610939323, 56.80445610939323, 64.58941130666561, 64.58941130666561, 56.80445610939323, 64.58941130666561, 56.80445610939323, 56.80445610939323, 64.58941130666561, 56.80445610939323, 56.80445610939323, 56.80445610939323] [43.75872112626925, 92.5596638292661, 43.75872112626925, 92.5596638292661, 92.5596638292661, 43.75872112626925, 43.75872112626925, 92.5596638292661, 43.75872112626925, 92.5596638292661, 92.5596638292661, 43.75872112626925, 92.5596638292661, 92.5596638292661, 43.75872112626925]\n"
     ]
    }
   ],
   "source": [
    "import pygad\n",
    "\n",
    "max__ = []\n",
    "lr__ = []\n",
    "mcs__ = []\n",
    "md__ = []\n",
    "nl__ = []\n",
    "cb__ = []\n",
    "ra__ = []\n",
    "rl__ = []\n",
    "\n",
    "for i in tqdm_notebook(range(0, 1500, 100)):\n",
    "    name = \"data_bow_nt_\" + str(i) + '.csv'\n",
    "    data = pd.read_csv(name)\n",
    "    \n",
    "    max_ = {'max': 0, \n",
    "           'learning_rate': 0,\n",
    "           'min_child_samples': 0,              \n",
    "           'max_depth': 0,\n",
    "           'num_leaves': 0, \n",
    "           'colsample_bytree': 0,\n",
    "           'reg_alpha': 0,\n",
    "           'reg_lambda': 0}\n",
    "    \n",
    "    category_col = ['attacktype1_txt', 'targsubtype1_txt', 'weapsubtype1_txt']\n",
    "    data[category_col] = data[category_col].astype('category')\n",
    "    X = data.drop(columns=['risk'], axis=1)\n",
    "    y = data['risk']\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    splits = kf.split(X, y)\n",
    "    \n",
    "    for k, (train_indices, test_indices) in enumerate(splits):\n",
    "        print(\"第 %d 折\\n\" % (k + 1))\n",
    "        X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "        y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "        labels = [0, 1, 2, 3]\n",
    "        y_one_hot = label_binarize(y_test, classes=labels)\n",
    "        \n",
    "        param_list = [\n",
    "        {'low': 0.01, 'high': 1}, # learning_rate \n",
    "        {'low': 5, 'high': 50}, # min_child_samples\n",
    "        {'low': 1, 'high': 15}, # max_depth \n",
    "        {'low': 5, 'high':100}, #num_leaves \n",
    "        {'low': 0.1, 'high': 1}, #colsample_bytree\n",
    "        {'low': 0, 'high': 100}, # reg_alpha\n",
    "        {'low': 0, 'high': 100}, #reg_lambda\n",
    "        ]\n",
    "    \n",
    "        # 定义遗传算法\n",
    "        ga_instance = pygad.GA(num_generations=4, # 遗传算法的代数 \n",
    "                               num_parents_mating=2, # 每代选择交叉的父代数量 \n",
    "                               fitness_func=fitness_func, # 适应函数 \n",
    "        #                            initial_population=[20, 8],\n",
    "                               sol_per_pop=3, # 种群中的解决方案数量 \n",
    "                               num_genes=len(param_list), # 解决方案中的基因数量（即超参数数量） \n",
    "                               gene_type=float, # 基因类型（即超参数类型） \n",
    "                               gene_space=param_list, # 基因空间（即超参数范围） \n",
    "                               parent_selection_type='rws', # 父代选择类型 \n",
    "                               keep_parents=1, # 保留的父代数量 \n",
    "                               crossover_type='uniform', # 交叉类型 \n",
    "                               crossover_probability=0.6,\n",
    "                               mutation_type='random', # 变异类型 \n",
    "                               mutation_probability=0.01,\n",
    "        #                            mutation_percent_genes=10 # 变异基因百分比\n",
    "                               random_seed=0\n",
    "                              )\n",
    "        # 开始遗传算法\n",
    "        ga_instance.run()\n",
    "        \n",
    "        # 获取最优超参数组合\n",
    "        best_solution, best_fitness, best_solution_idx = ga_instance.best_solution()\n",
    "        best_learning_rate = best_solution[0] \n",
    "        best_min_child_samples = int(best_solution[1])\n",
    "        best_max_depth = int(best_solution[2])\n",
    "        best_num_leaves = int(best_solution[3])\n",
    "        best_colsample_bytree = (best_solution[4])\n",
    "        best_reg_alpha = best_solution[5]\n",
    "        best_reg_lambda = best_solution[6]\n",
    "\n",
    "        # 打印最佳解决方案和最佳适应值\n",
    "        print('Best solution is {solution} with fitness value {fitness}'.format(solution=best_solution, fitness=best_fitness)) \n",
    "        print('Best learning rate is {lr}'.format(lr=best_learning_rate)) \n",
    "        print('Best min child samples is {mcs}'.format(mcs=best_min_child_samples))\n",
    "        print('Best max depth is {md}'.format(md=best_max_depth)) \n",
    "        print('Best num leaves is {nl}'.format(nl=best_num_leaves))  \n",
    "        print('Best colsample bytree is {cb}'.format(cb=best_colsample_bytree))\n",
    "        print('Best reg_alpha is {al}'.format(al=best_reg_alpha))\n",
    "        print('Best reg_lambda is {la}'.format(la=best_reg_lambda))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        if best_fitness > max_['max']:\n",
    "            max_['max'] = best_fitness\n",
    "            max_['learning_rate'] = best_learning_rate \n",
    "            max_['min_child_samples'] = best_min_child_samples\n",
    "            max_['max_depth'] = best_max_depth\n",
    "            max_['num_leaves'] = best_num_leaves\n",
    "            max_['colsample_bytree'] = best_colsample_bytree\n",
    "            max_['reg_alpha'] = best_reg_alpha\n",
    "            max_['reg_lambda'] = best_reg_lambda\n",
    "            \n",
    "    max__.append(max_['max'])\n",
    "    lr__.append(max_['learning_rate'])\n",
    "    mcs__.append(max_['min_child_samples'])\n",
    "    md__.append(max_['max_depth'])\n",
    "    nl__.append(max_['num_leaves'])\n",
    "    cb__.append(max_['colsample_bytree'])\n",
    "    ra__.append(max_['reg_alpha'])\n",
    "    rl__.append(max_['reg_lambda'])\n",
    "        \n",
    "print(max__, lr__, mcs__, md__, nl__, cb__, ra__, rl__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae048be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6657477601654032, 0.7291523087525844, 0.743762922122674, 0.7455547898001378, 0.7478980013783597, 0.7441764300482426, 0.7456926257753274, 0.749276361130255, 0.7474844934527912, 0.7485871812543073, 0.749276361130255, 0.7502412129565816, 0.7494141971054445, 0.7498277050310131, 0.7507925568573398]\n"
     ]
    }
   ],
   "source": [
    "print(max__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2add560",
   "metadata": {},
   "outputs": [],
   "source": [
    "max__ = [0.6657477601654032, 0.7291523087525844, 0.743762922122674, 0.7455547898001378, 0.7478980013783597, 0.7441764300482426, 0.7456926257753274, 0.749276361130255, 0.7474844934527912, 0.7485871812543073, 0.749276361130255, 0.7502412129565816, 0.7494141971054445, 0.7498277050310131, 0.7507925568573398] \n",
    "lr__ = [0.5533253688880515, 0.892855270774259, 0.5533253688880515, 0.892855270774259, 0.892855270774259, 0.5533253688880515, 0.5533253688880515, 0.892855270774259, 0.5533253688880515, 0.892855270774259, 0.892855270774259, 0.5533253688880515, 0.892855270774259, 0.892855270774259, 0.5533253688880515] \n",
    "mcs__ = [37, 48, 37, 48, 48, 37, 48, 48, 37, 48, 48, 37, 37, 48, 37] \n",
    "md__ = [9, 6, 9, 6, 6, 9, 9, 6, 9, 6, 6, 9, 6, 6, 9] \n",
    "nl__ = [80, 80, 80, 80, 80, 80, 56, 80, 80, 80, 80, 56, 80, 80, 80] \n",
    "cb__ = [0.7616746199103354, 0.5760054277776141, 0.7616746199103354, 0.5760054277776141, 0.5760054277776141, 0.7616746199103354, 0.7616746199103354, 0.5760054277776141, 0.7616746199103354, 0.5760054277776141, 0.5760054277776141, 0.4812893194050143, 0.7616746199103354, 0.5760054277776141, 0.4812893194050143] \n",
    "ra__ = [64.58941130666561, 56.80445610939323, 56.80445610939323, 56.80445610939323, 56.80445610939323, 64.58941130666561, 64.58941130666561, 56.80445610939323, 64.58941130666561, 56.80445610939323, 56.80445610939323, 64.58941130666561, 56.80445610939323, 56.80445610939323, 56.80445610939323] \n",
    "rl__ = [43.75872112626925, 92.5596638292661, 43.75872112626925, 92.5596638292661, 92.5596638292661, 43.75872112626925, 43.75872112626925, 92.5596638292661, 43.75872112626925, 92.5596638292661, 92.5596638292661, 43.75872112626925, 92.5596638292661, 92.5596638292661, 43.75872112626925]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89baf658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02393651008605957,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 15,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f2eeb6a6aa48d990fd1c452b7f433a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 85.8203385658022%\n",
      " ACC: 66.10613370089592%\n",
      " F1: 65.38838699531145%\n",
      " RECALL: 66.10613370089592%\n",
      " PRECISION: 65.2823793900078%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 85.68169589008116%\n",
      " ACC: 65.16884906960718%\n",
      " F1: 64.51924163171235%\n",
      " RECALL: 65.16884906960718%\n",
      " PRECISION: 64.56169792549115%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 86.02516852805526%\n",
      " ACC: 65.26533425223984%\n",
      " F1: 64.62498723706126%\n",
      " RECALL: 65.26533425223984%\n",
      " PRECISION: 64.74274909751783%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 86.14994448721146%\n",
      " ACC: 65.73397656788423%\n",
      " F1: 65.12605096813078%\n",
      " RECALL: 65.73397656788423%\n",
      " PRECISION: 65.2392289353695%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 86.4614149902275%\n",
      " ACC: 65.70640937284631%\n",
      " F1: 64.8898762391123%\n",
      " RECALL: 65.70640937284631%\n",
      " PRECISION: 64.8517698610826%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 86.00557159858087%\n",
      " ACC: 65.48587181254307%\n",
      " F1: 64.81125495871167%\n",
      " RECALL: 65.48587181254307%\n",
      " PRECISION: 64.79430502842466%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 86.22343578054782%\n",
      " ACC: 65.78911095796003%\n",
      " F1: 65.22985644503713%\n",
      " RECALL: 65.78911095796003%\n",
      " PRECISION: 65.25464717722605%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 85.88527826972339%\n",
      " ACC: 65.77532736044107%\n",
      " F1: 65.15798637900293%\n",
      " RECALL: 65.77532736044107%\n",
      " PRECISION: 65.28221803933849%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 86.28977128611953%\n",
      " ACC: 66.57477601654031%\n",
      " F1: 65.97521410754054%\n",
      " RECALL: 66.57477601654031%\n",
      " PRECISION: 66.00149076652137%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 85.60269241860755%\n",
      " ACC: 65.14128187456927%\n",
      " F1: 64.42599346118398%\n",
      " RECALL: 65.14128187456927%\n",
      " PRECISION: 64.63091059960438%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 89.39565962497636%\n",
      " ACC: 71.19228118538939%\n",
      " F1: 71.03217106374477%\n",
      " RECALL: 71.19228118538939%\n",
      " PRECISION: 71.16617004178322%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 89.83121063195415%\n",
      " ACC: 72.17091660923501%\n",
      " F1: 71.97641463568803%\n",
      " RECALL: 72.17091660923501%\n",
      " PRECISION: 72.1589379844518%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.11158021088299%\n",
      " ACC: 71.99172984148862%\n",
      " F1: 71.82708913794784%\n",
      " RECALL: 71.99172984148862%\n",
      " PRECISION: 72.01367751140701%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 90.32974595364621%\n",
      " ACC: 72.33631977946244%\n",
      " F1: 72.21180515494416%\n",
      " RECALL: 72.33631977946244%\n",
      " PRECISION: 72.31555092692832%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 90.36049289744304%\n",
      " ACC: 72.30875258442452%\n",
      " F1: 72.07993384971371%\n",
      " RECALL: 72.30875258442452%\n",
      " PRECISION: 72.28837638428938%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 89.73814492079227%\n",
      " ACC: 72.36388697450035%\n",
      " F1: 72.19093724482116%\n",
      " RECALL: 72.36388697450035%\n",
      " PRECISION: 72.41847883369786%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.1969665237208%\n",
      " ACC: 72.6671261199173%\n",
      " F1: 72.5359604446938%\n",
      " RECALL: 72.6671261199173%\n",
      " PRECISION: 72.64166174250019%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.01133408220508%\n",
      " ACC: 72.91523087525844%\n",
      " F1: 72.7763835772434%\n",
      " RECALL: 72.91523087525844%\n",
      " PRECISION: 73.08363058935564%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 90.0542299763796%\n",
      " ACC: 72.0882150241213%\n",
      " F1: 71.91028695888711%\n",
      " RECALL: 72.0882150241213%\n",
      " PRECISION: 72.07859694951259%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 89.95486602006116%\n",
      " ACC: 71.89524465885596%\n",
      " F1: 71.72796826061571%\n",
      " RECALL: 71.89524465885596%\n",
      " PRECISION: 71.89842528222592%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.64204942311628%\n",
      " ACC: 73.70089593383872%\n",
      " F1: 73.58269281109283%\n",
      " RECALL: 73.70089593383872%\n",
      " PRECISION: 73.72107391892293%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.81374491147571%\n",
      " ACC: 73.7973811164714%\n",
      " F1: 73.65322767995224%\n",
      " RECALL: 73.7973811164714%\n",
      " PRECISION: 73.8949910813478%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.90755719681145%\n",
      " ACC: 73.46657477601653%\n",
      " F1: 73.33627999052632%\n",
      " RECALL: 73.46657477601653%\n",
      " PRECISION: 73.56022190173356%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 90.94570271878038%\n",
      " ACC: 73.75603032391454%\n",
      " F1: 73.65878368258136%\n",
      " RECALL: 73.75603032391454%\n",
      " PRECISION: 73.84510253603796%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.36805924455834%\n",
      " ACC: 74.18332184700208%\n",
      " F1: 74.0177242410006%\n",
      " RECALL: 74.18332184700208%\n",
      " PRECISION: 74.23081136467296%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.7471033558713%\n",
      " ACC: 73.49414197105445%\n",
      " F1: 73.36558810494915%\n",
      " RECALL: 73.49414197105445%\n",
      " PRECISION: 73.64201136776465%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 91.08819004254543%\n",
      " ACC: 74.12818745692626%\n",
      " F1: 74.03544862559316%\n",
      " RECALL: 74.12818745692626%\n",
      " PRECISION: 74.14722041371984%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.87201209547902%\n",
      " ACC: 73.89386629910406%\n",
      " F1: 73.82098496918165%\n",
      " RECALL: 73.89386629910406%\n",
      " PRECISION: 74.08187449544091%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 91.15541750586665%\n",
      " ACC: 74.3762922122674%\n",
      " F1: 74.27110612574123%\n",
      " RECALL: 74.3762922122674%\n",
      " PRECISION: 74.47052505792678%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.7305799823217%\n",
      " ACC: 73.2460372157133%\n",
      " F1: 73.13278650014142%\n",
      " RECALL: 73.2460372157133%\n",
      " PRECISION: 73.30918853731514%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.60373398822426%\n",
      " ACC: 73.1909028256375%\n",
      " F1: 73.04414028018053%\n",
      " RECALL: 73.1909028256375%\n",
      " PRECISION: 73.19846763794965%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.80574660263956%\n",
      " ACC: 73.90764989662301%\n",
      " F1: 73.74695856998554%\n",
      " RECALL: 73.90764989662301%\n",
      " PRECISION: 73.98938808734523%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.9632877271162%\n",
      " ACC: 73.72846312887664%\n",
      " F1: 73.59883335575593%\n",
      " RECALL: 73.72846312887664%\n",
      " PRECISION: 73.77210417327335%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.08631908070133%\n",
      " ACC: 74.21088904203998%\n",
      " F1: 74.1255734412722%\n",
      " RECALL: 74.21088904203998%\n",
      " PRECISION: 74.25635168977843%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.403607170773%\n",
      " ACC: 74.29359062715368%\n",
      " F1: 74.11509486704408%\n",
      " RECALL: 74.29359062715368%\n",
      " PRECISION: 74.31812276823212%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.55908257446204%\n",
      " ACC: 73.32873880082703%\n",
      " F1: 73.16783474933301%\n",
      " RECALL: 73.32873880082703%\n",
      " PRECISION: 73.39699856095775%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 90.89556557903407%\n",
      " ACC: 73.89386629910406%\n",
      " F1: 73.77966773244533%\n",
      " RECALL: 73.89386629910406%\n",
      " PRECISION: 73.91549505270643%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.79788796132418%\n",
      " ACC: 73.49414197105445%\n",
      " F1: 73.39472138326559%\n",
      " RECALL: 73.49414197105445%\n",
      " PRECISION: 73.68832056115495%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 91.14931643045284%\n",
      " ACC: 74.55547898001377%\n",
      " F1: 74.42681582797141%\n",
      " RECALL: 74.55547898001377%\n",
      " PRECISION: 74.60431656372393%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.8247145191516%\n",
      " ACC: 73.60441075120606%\n",
      " F1: 73.48147236691872%\n",
      " RECALL: 73.60441075120606%\n",
      " PRECISION: 73.68131863800895%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.44386558596553%\n",
      " ACC: 73.59062715368711%\n",
      " F1: 73.4727635291221%\n",
      " RECALL: 73.59062715368711%\n",
      " PRECISION: 73.62197467052718%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.97004053321481%\n",
      " ACC: 74.0592694693315%\n",
      " F1: 73.93235572642728%\n",
      " RECALL: 74.0592694693315%\n",
      " PRECISION: 74.19946686935165%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.94798147114051%\n",
      " ACC: 73.39765678842178%\n",
      " F1: 73.26301387426234%\n",
      " RECALL: 73.39765678842178%\n",
      " PRECISION: 73.49105366408628%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.0790275426703%\n",
      " ACC: 73.7973811164714%\n",
      " F1: 73.71471107775109%\n",
      " RECALL: 73.7973811164714%\n",
      " PRECISION: 73.85742464501273%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.41833697331936%\n",
      " ACC: 74.78980013783597%\n",
      " F1: 74.62569856228423%\n",
      " RECALL: 74.78980013783597%\n",
      " PRECISION: 74.8123110972671%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.45591277437892%\n",
      " ACC: 73.05306685044796%\n",
      " F1: 72.91902950702102%\n",
      " RECALL: 73.05306685044796%\n",
      " PRECISION: 73.13013762777543%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 91.11085073709526%\n",
      " ACC: 74.23845623707788%\n",
      " F1: 74.13837678340487%\n",
      " RECALL: 74.23845623707788%\n",
      " PRECISION: 74.2423234811138%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.7249249309284%\n",
      " ACC: 73.8249483115093%\n",
      " F1: 73.73685440831642%\n",
      " RECALL: 73.8249483115093%\n",
      " PRECISION: 73.96288438770735%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 91.161082238798%\n",
      " ACC: 74.55547898001377%\n",
      " F1: 74.45456836402825%\n",
      " RECALL: 74.55547898001377%\n",
      " PRECISION: 74.63751059216474%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.6930624134907%\n",
      " ACC: 73.45279117849759%\n",
      " F1: 73.32326975774009%\n",
      " RECALL: 73.45279117849759%\n",
      " PRECISION: 73.60269424381407%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.65603589329719%\n",
      " ACC: 73.5079255685734%\n",
      " F1: 73.38905277746142%\n",
      " RECALL: 73.5079255685734%\n",
      " PRECISION: 73.49175437370117%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.96966953473459%\n",
      " ACC: 73.61819434872501%\n",
      " F1: 73.521269129443%\n",
      " RECALL: 73.61819434872501%\n",
      " PRECISION: 73.73247339419768%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 91.08189824990792%\n",
      " ACC: 73.64576154376292%\n",
      " F1: 73.52499338841083%\n",
      " RECALL: 73.64576154376292%\n",
      " PRECISION: 73.79682029172474%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.0354631326927%\n",
      " ACC: 73.94900068917988%\n",
      " F1: 73.85869630258158%\n",
      " RECALL: 73.94900068917988%\n",
      " PRECISION: 74.06558996091844%\n",
      "第 5 折\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold 5 | \n",
      " AUC_ROC: 91.3584455840734%\n",
      " ACC: 74.3762922122674%\n",
      " F1: 74.22737908812236%\n",
      " RECALL: 74.3762922122674%\n",
      " PRECISION: 74.44893176293228%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.87956230673221%\n",
      " ACC: 73.63197794624396%\n",
      " F1: 73.52204748048162%\n",
      " RECALL: 73.63197794624396%\n",
      " PRECISION: 73.79384733782442%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 91.18482103387068%\n",
      " ACC: 74.14197105444521%\n",
      " F1: 74.04271062976868%\n",
      " RECALL: 74.14197105444521%\n",
      " PRECISION: 74.15412180342372%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.78365355500469%\n",
      " ACC: 73.81116471399035%\n",
      " F1: 73.70533198502949%\n",
      " RECALL: 73.81116471399035%\n",
      " PRECISION: 73.98318955394679%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 91.10731271740596%\n",
      " ACC: 74.41764300482426%\n",
      " F1: 74.32500583719265%\n",
      " RECALL: 74.41764300482426%\n",
      " PRECISION: 74.49408850546993%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.8512531018529%\n",
      " ACC: 73.0117160578911%\n",
      " F1: 72.90458258545497%\n",
      " RECALL: 73.0117160578911%\n",
      " PRECISION: 73.17609852108772%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.64748372181587%\n",
      " ACC: 73.31495520330806%\n",
      " F1: 73.20614935245548%\n",
      " RECALL: 73.31495520330806%\n",
      " PRECISION: 73.3374835653861%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 91.10769135193128%\n",
      " ACC: 73.83873190902825%\n",
      " F1: 73.72815859426724%\n",
      " RECALL: 73.83873190902825%\n",
      " PRECISION: 73.93797627123705%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.98930008206449%\n",
      " ACC: 73.59062715368711%\n",
      " F1: 73.43592417262923%\n",
      " RECALL: 73.59062715368711%\n",
      " PRECISION: 73.71585560076421%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.0999078804626%\n",
      " ACC: 73.86629910406616%\n",
      " F1: 73.7708536132051%\n",
      " RECALL: 73.86629910406616%\n",
      " PRECISION: 73.92797750788898%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.53271694373856%\n",
      " ACC: 74.41764300482426%\n",
      " F1: 74.26230051722557%\n",
      " RECALL: 74.41764300482426%\n",
      " PRECISION: 74.4522325125818%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.76521509750197%\n",
      " ACC: 73.25982081323225%\n",
      " F1: 73.12729533562687%\n",
      " RECALL: 73.25982081323225%\n",
      " PRECISION: 73.34991727930172%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 91.26334486887171%\n",
      " ACC: 74.23845623707788%\n",
      " F1: 74.15815509796589%\n",
      " RECALL: 74.23845623707788%\n",
      " PRECISION: 74.27865884433324%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 91.09559997801927%\n",
      " ACC: 74.16953824948311%\n",
      " F1: 74.10805909457471%\n",
      " RECALL: 74.16953824948311%\n",
      " PRECISION: 74.40055925658875%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 91.0947956843423%\n",
      " ACC: 74.56926257753274%\n",
      " F1: 74.47094051964268%\n",
      " RECALL: 74.56926257753274%\n",
      " PRECISION: 74.69711624178713%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.63419779674449%\n",
      " ACC: 72.9290144727774%\n",
      " F1: 72.80595441109014%\n",
      " RECALL: 72.9290144727774%\n",
      " PRECISION: 73.05056776366688%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.64859523198507%\n",
      " ACC: 73.32873880082703%\n",
      " F1: 73.20972442296096%\n",
      " RECALL: 73.32873880082703%\n",
      " PRECISION: 73.32478558621028%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.99865014578222%\n",
      " ACC: 73.92143349414198%\n",
      " F1: 73.77854949522316%\n",
      " RECALL: 73.92143349414198%\n",
      " PRECISION: 73.99401582752309%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.87649768187754%\n",
      " ACC: 73.14955203308064%\n",
      " F1: 72.99070780427658%\n",
      " RECALL: 73.14955203308064%\n",
      " PRECISION: 73.16684349549566%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.00009983506042%\n",
      " ACC: 73.92143349414198%\n",
      " F1: 73.82498644885767%\n",
      " RECALL: 73.92143349414198%\n",
      " PRECISION: 73.9826136695613%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.5818578535843%\n",
      " ACC: 74.52791178497587%\n",
      " F1: 74.34524914203256%\n",
      " RECALL: 74.52791178497587%\n",
      " PRECISION: 74.56305941337757%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.68799608252642%\n",
      " ACC: 73.13576843556167%\n",
      " F1: 72.99964827372601%\n",
      " RECALL: 73.13576843556167%\n",
      " PRECISION: 73.20999631419912%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 91.20201195251553%\n",
      " ACC: 74.0592694693315%\n",
      " F1: 73.95892533182047%\n",
      " RECALL: 74.0592694693315%\n",
      " PRECISION: 74.05485913484571%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 91.00073575895371%\n",
      " ACC: 74.30737422467264%\n",
      " F1: 74.23980430876603%\n",
      " RECALL: 74.30737422467264%\n",
      " PRECISION: 74.4657745268469%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 91.29124499679654%\n",
      " ACC: 74.9276361130255%\n",
      " F1: 74.8352043191244%\n",
      " RECALL: 74.9276361130255%\n",
      " PRECISION: 75.0132848481709%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.85333988269674%\n",
      " ACC: 73.71467953135769%\n",
      " F1: 73.57716364106963%\n",
      " RECALL: 73.71467953135769%\n",
      " PRECISION: 73.83087249585823%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.74032829692018%\n",
      " ACC: 73.74224672639559%\n",
      " F1: 73.63437252286083%\n",
      " RECALL: 73.74224672639559%\n",
      " PRECISION: 73.72865587072485%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.82708282026626%\n",
      " ACC: 73.42522398345969%\n",
      " F1: 73.32470948859266%\n",
      " RECALL: 73.42522398345969%\n",
      " PRECISION: 73.53549522684081%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.9704476896389%\n",
      " ACC: 73.42522398345969%\n",
      " F1: 73.30015664425609%\n",
      " RECALL: 73.42522398345969%\n",
      " PRECISION: 73.4920778322149%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.10631781346117%\n",
      " ACC: 73.96278428669882%\n",
      " F1: 73.86277148744556%\n",
      " RECALL: 73.96278428669882%\n",
      " PRECISION: 74.01849614615979%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.45915650072423%\n",
      " ACC: 74.74844934527913%\n",
      " F1: 74.5826795119144%\n",
      " RECALL: 74.74844934527913%\n",
      " PRECISION: 74.80451297923807%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.82065361025884%\n",
      " ACC: 73.75603032391454%\n",
      " F1: 73.62263624003944%\n",
      " RECALL: 73.75603032391454%\n",
      " PRECISION: 73.93550521758209%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 91.15288914155374%\n",
      " ACC: 74.0592694693315%\n",
      " F1: 73.95630193938479%\n",
      " RECALL: 74.0592694693315%\n",
      " PRECISION: 74.07170932841822%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.95626901174217%\n",
      " ACC: 73.96278428669882%\n",
      " F1: 73.90220730744622%\n",
      " RECALL: 73.96278428669882%\n",
      " PRECISION: 74.19601604042359%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 91.21290911449297%\n",
      " ACC: 74.33494141971055%\n",
      " F1: 74.22975289763933%\n",
      " RECALL: 74.33494141971055%\n",
      " PRECISION: 74.40555137225083%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.79729106247053%\n",
      " ACC: 73.30117160578911%\n",
      " F1: 73.18533671176962%\n",
      " RECALL: 73.30117160578911%\n",
      " PRECISION: 73.40884475469997%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.66243959715085%\n",
      " ACC: 73.54927636113025%\n",
      " F1: 73.447765306402%\n",
      " RECALL: 73.54927636113025%\n",
      " PRECISION: 73.56260803862938%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 91.02795610556227%\n",
      " ACC: 74.14197105444521%\n",
      " F1: 74.01791584605114%\n",
      " RECALL: 74.14197105444521%\n",
      " PRECISION: 74.18738346223141%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 91.0852081205711%\n",
      " ACC: 73.57684355616816%\n",
      " F1: 73.42414705435596%\n",
      " RECALL: 73.57684355616816%\n",
      " PRECISION: 73.61896241338012%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.13908219481891%\n",
      " ACC: 74.47277739490006%\n",
      " F1: 74.37475849537243%\n",
      " RECALL: 74.47277739490006%\n",
      " PRECISION: 74.55074202617297%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.49512183008352%\n",
      " ACC: 74.44521019986216%\n",
      " F1: 74.2737903878343%\n",
      " RECALL: 74.44521019986216%\n",
      " PRECISION: 74.45783150908056%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.80367847658152%\n",
      " ACC: 73.86629910406616%\n",
      " F1: 73.74340031535088%\n",
      " RECALL: 73.86629910406616%\n",
      " PRECISION: 73.93769404166278%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 91.11747398233081%\n",
      " ACC: 74.72088215024121%\n",
      " F1: 74.6455659622711%\n",
      " RECALL: 74.72088215024121%\n",
      " PRECISION: 74.74836296847994%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.84857239699507%\n",
      " ACC: 73.64576154376292%\n",
      " F1: 73.54309530890274%\n",
      " RECALL: 73.64576154376292%\n",
      " PRECISION: 73.73170238655263%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 91.20451422091563%\n",
      " ACC: 74.85871812543074%\n",
      " F1: 74.77821016766218%\n",
      " RECALL: 74.85871812543074%\n",
      " PRECISION: 74.91059755626725%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.87218441138897%\n",
      " ACC: 73.57684355616816%\n",
      " F1: 73.45346923771241%\n",
      " RECALL: 73.57684355616816%\n",
      " PRECISION: 73.74779885825298%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.74902062142394%\n",
      " ACC: 73.56305995864922%\n",
      " F1: 73.45784078173911%\n",
      " RECALL: 73.56305995864922%\n",
      " PRECISION: 73.56756558091917%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 91.05192949752892%\n",
      " ACC: 74.19710544452101%\n",
      " F1: 74.08331719895051%\n",
      " RECALL: 74.19710544452101%\n",
      " PRECISION: 74.28244668735144%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 91.10951757006859%\n",
      " ACC: 73.5079255685734%\n",
      " F1: 73.32847718297238%\n",
      " RECALL: 73.5079255685734%\n",
      " PRECISION: 73.61739235191916%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.14378428800175%\n",
      " ACC: 73.68711233631979%\n",
      " F1: 73.58507594040101%\n",
      " RECALL: 73.68711233631979%\n",
      " PRECISION: 73.76521275667261%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.54299855969383%\n",
      " ACC: 74.9276361130255%\n",
      " F1: 74.73872850805517%\n",
      " RECALL: 74.9276361130255%\n",
      " PRECISION: 74.96756634626408%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.83441912710983%\n",
      " ACC: 73.7698139214335%\n",
      " F1: 73.62155905617816%\n",
      " RECALL: 73.7698139214335%\n",
      " PRECISION: 73.80587408206972%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 91.31950442260248%\n",
      " ACC: 74.59682977257064%\n",
      " F1: 74.48775127348136%\n",
      " RECALL: 74.59682977257064%\n",
      " PRECISION: 74.66044831766222%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.85907824442037%\n",
      " ACC: 74.52791178497587%\n",
      " F1: 74.4561655325296%\n",
      " RECALL: 74.52791178497587%\n",
      " PRECISION: 74.71104038376943%\n",
      "第 9 折\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold 9 | \n",
      " AUC_ROC: 91.26856793097178%\n",
      " ACC: 74.6381805651275%\n",
      " F1: 74.54976834048304%\n",
      " RECALL: 74.6381805651275%\n",
      " PRECISION: 74.72515934847567%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.79404942187132%\n",
      " ACC: 73.20468642315645%\n",
      " F1: 73.079145525863%\n",
      " RECALL: 73.20468642315645%\n",
      " PRECISION: 73.32396462487421%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.73903824578521%\n",
      " ACC: 73.65954514128188%\n",
      " F1: 73.54774305165137%\n",
      " RECALL: 73.65954514128188%\n",
      " PRECISION: 73.69903428325557%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.93196991696868%\n",
      " ACC: 74.0868366643694%\n",
      " F1: 73.99087538854741%\n",
      " RECALL: 74.0868366643694%\n",
      " PRECISION: 74.19219898654369%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.87837464784327%\n",
      " ACC: 73.10820124052377%\n",
      " F1: 72.9762034399065%\n",
      " RECALL: 73.10820124052377%\n",
      " PRECISION: 73.22037151859907%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.2411354025897%\n",
      " ACC: 74.15575465196417%\n",
      " F1: 74.07707562315721%\n",
      " RECALL: 74.15575465196417%\n",
      " PRECISION: 74.24850922983683%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.35262220400854%\n",
      " ACC: 74.16953824948311%\n",
      " F1: 73.96899024963109%\n",
      " RECALL: 74.16953824948311%\n",
      " PRECISION: 74.25321073541092%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.72259349922362%\n",
      " ACC: 73.45279117849759%\n",
      " F1: 73.31622537697503%\n",
      " RECALL: 73.45279117849759%\n",
      " PRECISION: 73.58300007698922%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 91.20872813033385%\n",
      " ACC: 74.6106133700896%\n",
      " F1: 74.52948030111737%\n",
      " RECALL: 74.6106133700896%\n",
      " PRECISION: 74.69183350417264%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 91.17806416157312%\n",
      " ACC: 74.43142660234321%\n",
      " F1: 74.36578978041418%\n",
      " RECALL: 74.43142660234321%\n",
      " PRECISION: 74.67261787678235%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 91.16089188737878%\n",
      " ACC: 75.02412129565816%\n",
      " F1: 74.94128923979882%\n",
      " RECALL: 75.02412129565816%\n",
      " PRECISION: 75.1180536128049%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.8473068659705%\n",
      " ACC: 73.78359751895245%\n",
      " F1: 73.6692557220783%\n",
      " RECALL: 73.78359751895245%\n",
      " PRECISION: 73.89868938049214%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.82650812483315%\n",
      " ACC: 73.67332873880082%\n",
      " F1: 73.57597459683197%\n",
      " RECALL: 73.67332873880082%\n",
      " PRECISION: 73.72838777092396%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 91.12481434369839%\n",
      " ACC: 74.25223983459684%\n",
      " F1: 74.1355015312573%\n",
      " RECALL: 74.25223983459684%\n",
      " PRECISION: 74.27053396836534%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.90316953066662%\n",
      " ACC: 73.56305995864922%\n",
      " F1: 73.44162844413002%\n",
      " RECALL: 73.56305995864922%\n",
      " PRECISION: 73.62521656777795%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.18557337180391%\n",
      " ACC: 74.04548587181255%\n",
      " F1: 73.94813727303503%\n",
      " RECALL: 74.04548587181255%\n",
      " PRECISION: 74.10019245023022%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.1122611755659%\n",
      " ACC: 73.86629910406616%\n",
      " F1: 73.71845597809012%\n",
      " RECALL: 73.86629910406616%\n",
      " PRECISION: 73.91159228333831%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.8378432951198%\n",
      " ACC: 74.01791867677464%\n",
      " F1: 73.90515045434006%\n",
      " RECALL: 74.01791867677464%\n",
      " PRECISION: 74.1158519576724%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 91.19052116979523%\n",
      " ACC: 74.44521019986216%\n",
      " F1: 74.3646015891561%\n",
      " RECALL: 74.44521019986216%\n",
      " PRECISION: 74.45680510741118%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 90.97106770372754%\n",
      " ACC: 74.15575465196417%\n",
      " F1: 74.09525157586056%\n",
      " RECALL: 74.15575465196417%\n",
      " PRECISION: 74.27949258587326%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 91.40594418395665%\n",
      " ACC: 74.94141971054445%\n",
      " F1: 74.85454899268835%\n",
      " RECALL: 74.94141971054445%\n",
      " PRECISION: 75.01835045739679%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.89869579771602%\n",
      " ACC: 74.18332184700208%\n",
      " F1: 74.08743540249596%\n",
      " RECALL: 74.18332184700208%\n",
      " PRECISION: 74.29181455493065%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.72763813382147%\n",
      " ACC: 73.67332873880082%\n",
      " F1: 73.58176159748048%\n",
      " RECALL: 73.67332873880082%\n",
      " PRECISION: 73.66454977365986%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 90.93153375149008%\n",
      " ACC: 74.0317022742936%\n",
      " F1: 73.89243857425866%\n",
      " RECALL: 74.0317022742936%\n",
      " PRECISION: 74.09078338672064%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 90.99228863024437%\n",
      " ACC: 74.00413507925569%\n",
      " F1: 73.86074473454114%\n",
      " RECALL: 74.00413507925569%\n",
      " PRECISION: 74.0632929405342%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.29999892340075%\n",
      " ACC: 74.10062026188835%\n",
      " F1: 74.0335354750321%\n",
      " RECALL: 74.10062026188835%\n",
      " PRECISION: 74.20784870094147%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.68537040402795%\n",
      " ACC: 74.98277050310132%\n",
      " F1: 74.8263762047772%\n",
      " RECALL: 74.98277050310132%\n",
      " PRECISION: 75.0954559116317%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 90.91765481764486%\n",
      " ACC: 73.93521709166092%\n",
      " F1: 73.77869007622348%\n",
      " RECALL: 73.93521709166092%\n",
      " PRECISION: 73.99050450452678%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 91.29397753862783%\n",
      " ACC: 74.33494141971055%\n",
      " F1: 74.25954621085968%\n",
      " RECALL: 74.33494141971055%\n",
      " PRECISION: 74.34134296550143%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 91.1171661668172%\n",
      " ACC: 74.74844934527913%\n",
      " F1: 74.64509983248001%\n",
      " RECALL: 74.74844934527913%\n",
      " PRECISION: 74.925738663313%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 91.25945454196551%\n",
      " ACC: 74.59682977257064%\n",
      " F1: 74.47719118561628%\n",
      " RECALL: 74.59682977257064%\n",
      " PRECISION: 74.63336353826922%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.93951264255328%\n",
      " ACC: 73.72846312887664%\n",
      " F1: 73.60751522320564%\n",
      " RECALL: 73.72846312887664%\n",
      " PRECISION: 73.80320934187472%\n",
      "第 1 折\n",
      "\n",
      " Fold 1 | \n",
      " AUC_ROC: 90.83617326563011%\n",
      " ACC: 73.70089593383872%\n",
      " F1: 73.56853115945567%\n",
      " RECALL: 73.70089593383872%\n",
      " PRECISION: 73.72784193332687%\n",
      "第 2 折\n",
      "\n",
      " Fold 2 | \n",
      " AUC_ROC: 91.17271949295811%\n",
      " ACC: 74.41764300482426%\n",
      " F1: 74.29251942275559%\n",
      " RECALL: 74.41764300482426%\n",
      " PRECISION: 74.49027653465153%\n",
      "第 3 折\n",
      "\n",
      " Fold 3 | \n",
      " AUC_ROC: 91.15878612202695%\n",
      " ACC: 73.67332873880082%\n",
      " F1: 73.53200192214176%\n",
      " RECALL: 73.67332873880082%\n",
      " PRECISION: 73.7840893800941%\n",
      "第 4 折\n",
      "\n",
      " Fold 4 | \n",
      " AUC_ROC: 91.3674674635554%\n",
      " ACC: 74.15575465196417%\n",
      " F1: 74.05810666748606%\n",
      " RECALL: 74.15575465196417%\n",
      " PRECISION: 74.2357001919526%\n",
      "第 5 折\n",
      "\n",
      " Fold 5 | \n",
      " AUC_ROC: 91.30458989599629%\n",
      " ACC: 74.21088904203998%\n",
      " F1: 74.03942054548092%\n",
      " RECALL: 74.21088904203998%\n",
      " PRECISION: 74.28566584548173%\n",
      "第 6 折\n",
      "\n",
      " Fold 6 | \n",
      " AUC_ROC: 91.06103141383929%\n",
      " ACC: 73.7973811164714%\n",
      " F1: 73.65238970760811%\n",
      " RECALL: 73.7973811164714%\n",
      " PRECISION: 73.93199449450599%\n",
      "第 7 折\n",
      "\n",
      " Fold 7 | \n",
      " AUC_ROC: 91.3966091316075%\n",
      " ACC: 74.77601654031703%\n",
      " F1: 74.67419805680845%\n",
      " RECALL: 74.77601654031703%\n",
      " PRECISION: 74.8073788714926%\n",
      "第 8 折\n",
      "\n",
      " Fold 8 | \n",
      " AUC_ROC: 91.22629932122027%\n",
      " ACC: 74.84493452791179%\n",
      " F1: 74.75529639962662%\n",
      " RECALL: 74.84493452791179%\n",
      " PRECISION: 74.98508629985804%\n",
      "第 9 折\n",
      "\n",
      " Fold 9 | \n",
      " AUC_ROC: 91.41952036861487%\n",
      " ACC: 75.07925568573398%\n",
      " F1: 75.00485242199831%\n",
      " RECALL: 75.07925568573398%\n",
      " PRECISION: 75.22100292594097%\n",
      "第 10 折\n",
      "\n",
      " Fold 10 | \n",
      " AUC_ROC: 90.92481183324061%\n",
      " ACC: 73.63197794624396%\n",
      " F1: 73.52278131247246%\n",
      " RECALL: 73.63197794624396%\n",
      " PRECISION: 73.81774598412478%\n",
      "[0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400]\n",
      "average roc score: [0.8601453118149568, 0.8999842308420616, 0.9092704164768263, 0.9090892616338792, 0.9090050852010017, 0.9099081151095723, 0.9102302534054925, 0.9101410294217785, 0.910043345061529, 0.9102562313363987, 0.9106728696836928, 0.9102607249616751, 0.9104563986968831, 0.9111645955505934, 0.9118680083086895]\n",
      "average acc_score: [0.6567470709855272, 0.7219297036526534, 0.7380427291523087, 0.7382081323225361, 0.7387594762232942, 0.7381116471399036, 0.7381943487250172, 0.7389937973811165, 0.7387181254307373, 0.7408545830461751, 0.7406202618883528, 0.7404824259131633, 0.7411440385940731, 0.7421364576154377, 0.7422880771881462]\n",
      "average f1_score: [0.6501488484228044, 0.7202689503282997, 0.73687462273076, 0.7368811125741722, 0.7375806415903579, 0.7370210692039466, 0.7370737907086828, 0.7377599631878574, 0.7376009247513489, 0.7397021180819152, 0.7393878293406534, 0.7393829281732772, 0.7401266858378854, 0.7409628991144748, 0.7411000976158341]\n",
      "average recall_score: [0.6567470709855272, 0.7219297036526534, 0.7380427291523087, 0.7382081323225361, 0.7387594762232942, 0.7381116471399036, 0.7381943487250172, 0.7389937973811165, 0.7387181254307373, 0.7408545830461751, 0.7406202618883528, 0.7404824259131633, 0.7411440385940731, 0.7421364576154377, 0.7422880771881462]\n",
      "average precision_score: [0.6506413968205838, 0.7220635062461519, 0.7389030206748826, 0.7388208837331309, 0.7395577812788202, 0.7391369155052269, 0.7391483448435359, 0.7396061053120887, 0.739596864768553, 0.7414536832607099, 0.7414266704799777, 0.7415775192048872, 0.7417982377039201, 0.742816089726973, 0.7432867824614292]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "roc_ = []\n",
    "acc_ = []\n",
    "f1_ = []\n",
    "recall_ = []\n",
    "precision_ = []\n",
    "ii = []\n",
    "\n",
    "for i in tqdm_notebook(range(0, 1500, 100)):\n",
    "    name = \"data_bow_nt_\" + str(i) + '.csv'\n",
    "    data = pd.read_csv(name)\n",
    "\n",
    "    category_col = ['attacktype1_txt', 'targsubtype1_txt', 'weapsubtype1_txt']\n",
    "    data[category_col] = data[category_col].astype('category')\n",
    "    X = data.drop(columns=['risk'], axis=1)\n",
    "    y = data['risk']\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    splits = kf.split(X, y)\n",
    "    \n",
    "    #lightGbm\n",
    "    lgb_roc_scores = []\n",
    "    lgb_acc_scores = []\n",
    "    lgb_f1_scores = []\n",
    "    lgb_recall_scores = []\n",
    "    lgb_precision_scores = []\n",
    "    lgb_feature_importances = pd.DataFrame(index=None)\n",
    "    lgb_feature_importances['features'] = data.drop(['risk'], axis=1).columns\n",
    "\n",
    "    for k, (train_indices, test_indices) in enumerate(splits):\n",
    "        print(\"第 %d 折\\n\" % (k + 1))\n",
    "        X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "        y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "        labels = [0, 1, 2, 3]\n",
    "        y_one_hot = label_binarize(y_test, classes=labels)\n",
    "\n",
    "        LGB = lgb.LGBMClassifier(random_state=0, \n",
    "                                 learning_rate=lr__[count], \n",
    "                                 min_child_samples=mcs__[count],\n",
    "                                 max_depth=md__[count], \n",
    "                                 num_leaves=nl__[count], \n",
    "                                 colsample_bytree=cb__[count],\n",
    "                                 reg_alpha=ra__[count],\n",
    "                                 reg_lambda=rl__[count],\n",
    "                                )\n",
    "        LGB.fit(X_train, y_train, categorical_feature=category_col)\n",
    "        lgb_feature_importances[f'fold_{k+1}'] = LGB.feature_importances_\n",
    "        y_pred_prob = LGB.predict_proba(X_test)\n",
    "        y_pred = LGB.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_one_hot, y_pred_prob, multi_class=\"ovo\", average='weighted')\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    #     G_mean = math.sqrt(recall * specificity)\n",
    "        print(f\" Fold {k + 1} | \" )\n",
    "        print(f\" AUC_ROC: { roc_auc * 100}%\" )\n",
    "        print(f\" ACC: { acc * 100}%\" )\n",
    "        print(f\" F1: { f1 * 100}%\" )\n",
    "        print(f\" RECALL: { recall * 100}%\" )\n",
    "        print(f\" PRECISION: { precision * 100}%\" )\n",
    "        lgb_f1_scores.append(f1)\n",
    "        lgb_roc_scores.append(roc_auc)\n",
    "        lgb_acc_scores.append(acc)\n",
    "        lgb_recall_scores.append(recall)\n",
    "        lgb_precision_scores.append(precision)\n",
    "    count = count + 1\n",
    "        \n",
    "    ii.append(i)\n",
    "    roc_.append(np.mean(lgb_roc_scores))\n",
    "    acc_.append(np.mean(lgb_acc_scores))\n",
    "    f1_.append(np.mean(lgb_f1_scores))\n",
    "    recall_.append(np.mean(lgb_recall_scores))\n",
    "    precision_.append(np.mean(lgb_precision_scores))\n",
    "#     print(f'average roc score: {np.mean(lgb_roc_scores)}')\n",
    "#     print(f'average acc_score: {np.mean(lgb_acc_scores)}')\n",
    "#     print(f'average f1_score: {np.mean(lgb_f1_scores)}')\n",
    "#     print(f'average recall_score: {np.mean(lgb_recall_scores)}')\n",
    "#     print(f'average precision_score: {np.mean(lgb_precision_scores)}')\n",
    "print(ii)\n",
    "print(f'average roc score: {roc_}')\n",
    "print(f'average acc_score: {acc_}')\n",
    "print(f'average f1_score: {f1_}')\n",
    "print(f'average recall_score: {recall_}')\n",
    "print(f'average precision_score: {precision_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c36e5f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8601453118149568, 0.8999842308420616, 0.9092704164768263, 0.9090892616338792, 0.9090050852010017, 0.9099081151095723, 0.9102302534054925, 0.9101410294217785, 0.910043345061529, 0.9102562313363987, 0.9106728696836928, 0.9102607249616751, 0.9104563986968831, 0.9111645955505934, 0.9118680083086895]\n",
      "[0.6567470709855272, 0.7219297036526534, 0.7380427291523087, 0.7382081323225361, 0.7387594762232942, 0.7381116471399036, 0.7381943487250172, 0.7389937973811165, 0.7387181254307373, 0.7408545830461751, 0.7406202618883528, 0.7404824259131633, 0.7411440385940731, 0.7421364576154377, 0.7422880771881462]\n",
      "[0.6501488484228044, 0.7202689503282997, 0.73687462273076, 0.7368811125741722, 0.7375806415903579, 0.7370210692039466, 0.7370737907086828, 0.7377599631878574, 0.7376009247513489, 0.7397021180819152, 0.7393878293406534, 0.7393829281732772, 0.7401266858378854, 0.7409628991144748, 0.7411000976158341]\n",
      "[0.6567470709855272, 0.7219297036526534, 0.7380427291523087, 0.7382081323225361, 0.7387594762232942, 0.7381116471399036, 0.7381943487250172, 0.7389937973811165, 0.7387181254307373, 0.7408545830461751, 0.7406202618883528, 0.7404824259131633, 0.7411440385940731, 0.7421364576154377, 0.7422880771881462]\n",
      "[0.6506413968205838, 0.7220635062461519, 0.7389030206748826, 0.7388208837331309, 0.7395577812788202, 0.7391369155052269, 0.7391483448435359, 0.7396061053120887, 0.739596864768553, 0.7414536832607099, 0.7414266704799777, 0.7415775192048872, 0.7417982377039201, 0.742816089726973, 0.7432867824614292]\n"
     ]
    }
   ],
   "source": [
    "print(roc_)\n",
    "print(acc_)\n",
    "print(f1_)\n",
    "print(recall_)\n",
    "print(precision_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ecb604f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8601453118149568, 0.8999842308420616, 0.9092704164768263, 0.9090892616338792, 0.9090050852010017, 0.9099081151095723, 0.9102302534054925, 0.9101410294217785, 0.910043345061529, 0.9102562313363987, 0.9106728696836928, 0.9102607249616751, 0.9104563986968831, 0.9111645955505934, 0.9118680083086895]\n",
      "[0.6567470709855272, 0.7219297036526534, 0.7380427291523087, 0.7382081323225361, 0.7387594762232942, 0.7381116471399036, 0.7381943487250172, 0.7389937973811165, 0.7387181254307373, 0.7408545830461751, 0.7406202618883528, 0.7404824259131633, 0.7411440385940731, 0.7421364576154377, 0.7422880771881462]\n",
      "[0.6501488484228044, 0.7202689503282997, 0.73687462273076, 0.7368811125741722, 0.7375806415903579, 0.7370210692039466, 0.7370737907086828, 0.7377599631878574, 0.7376009247513489, 0.7397021180819152, 0.7393878293406534, 0.7393829281732772, 0.7401266858378854, 0.7409628991144748, 0.7411000976158341]\n",
      "[0.6567470709855272, 0.7219297036526534, 0.7380427291523087, 0.7382081323225361, 0.7387594762232942, 0.7381116471399036, 0.7381943487250172, 0.7389937973811165, 0.7387181254307373, 0.7408545830461751, 0.7406202618883528, 0.7404824259131633, 0.7411440385940731, 0.7421364576154377, 0.7422880771881462]\n",
      "[0.6506413968205838, 0.7220635062461519, 0.7389030206748826, 0.7388208837331309, 0.7395577812788202, 0.7391369155052269, 0.7391483448435359, 0.7396061053120887, 0.739596864768553, 0.7414536832607099, 0.7414266704799777, 0.7415775192048872, 0.7417982377039201, 0.742816089726973, 0.7432867824614292]\n"
     ]
    }
   ],
   "source": [
    "print(roc_)\n",
    "print(acc_)\n",
    "print(f1_)\n",
    "print(recall_)\n",
    "print(precision_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1902c8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "#导入库\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "#设定画布。dpi越大图越清晰，绘图时间越久\n",
    "fig=plt.figure(figsize=(10, 4), dpi=200)\n",
    "#导入数据\n",
    "x = range(0, 1500, 100)\n",
    "x_ = range(0, 1500, 200)\n",
    "y_1 = np.arange(0.86, 0.91, 0.01)\n",
    "y_2 = np.arange(0.65, 0.76, 0.01)\n",
    "y1 = roc_\n",
    "y2 = acc_\n",
    "y3 = f1_\n",
    "y4 = recall_\n",
    "y5 = precision_\n",
    "#绘图命令\n",
    "plt.subplot(1,2,1) # 子图的行、列、索引\n",
    "plt.plot(x, y1, lw=1, ls='-', c='b', alpha=0.5, label='AUC')\n",
    "\n",
    "plt.legend()  \n",
    "plt.xticks(x_)\n",
    "plt.yticks(y_1)\n",
    "plt.title(\"Bag of word\")\n",
    "plt.xlabel(\"Feature dimension\") \n",
    "plt.ylabel(\"Performance\")\n",
    "\n",
    "plt.subplot(1,2,2) # 子图的行、列、索引\n",
    "plt.plot(x, y2, lw=1, ls='-', c='r', alpha=0.5, label='Accuracy')\n",
    "plt.plot(x, y3, lw=1, ls='-', c='g', alpha=0.5, label='F1-score')\n",
    "plt.plot(x, y4, lw=1, ls='-', c='k', alpha=0.5, label='Sensitivity')\n",
    "plt.plot(x, y5, lw=1, ls='-', c='m', alpha=0.5, label='Precision')\n",
    "\n",
    "plt.legend()  \n",
    "plt.xticks(x_)\n",
    "plt.yticks(y_2)\n",
    "plt.title(\"Bag of word\")\n",
    "plt.xlabel(\"Feature dimension\") \n",
    "plt.ylabel(\"Performance\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cced5809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9118680083086895\n",
      "0.7422880771881462\n",
      "0.7411000976158341\n",
      "0.7422880771881462\n",
      "0.7432867824614292\n"
     ]
    }
   ],
   "source": [
    "print(max(roc_))\n",
    "print(max(acc_))\n",
    "print(max(f1_))\n",
    "print(max(recall_))\n",
    "print(max(precision_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
